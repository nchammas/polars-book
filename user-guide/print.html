<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js ayu">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Polars - User Guide</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "ayu";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="quickstart/intro.html"><strong aria-hidden="true">2.</strong> Getting started</a></li><li class="chapter-item expanded "><a href="dsl/intro.html"><strong aria-hidden="true">3.</strong> Polars expressions</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="dsl/intro.html"><strong aria-hidden="true">3.1.</strong> Expressions</a></li><li class="chapter-item "><a href="dsl/contexts.html"><strong aria-hidden="true">3.2.</strong> Contexts</a></li><li class="chapter-item "><a href="dsl/groupby.html"><strong aria-hidden="true">3.3.</strong> GroupBy</a></li><li class="chapter-item "><a href="dsl/folds.html"><strong aria-hidden="true">3.4.</strong> Folds</a></li><li class="chapter-item "><a href="dsl/window_functions.html"><strong aria-hidden="true">3.5.</strong> Window functions</a></li><li class="chapter-item "><a href="dsl/numpy.html"><strong aria-hidden="true">3.6.</strong> Numpy universal functions</a></li><li class="chapter-item "><a href="notebooks/introduction_polars.html"><strong aria-hidden="true">3.7.</strong> Examples</a></li><li class="chapter-item "><a href="dsl/api.html"><strong aria-hidden="true">3.8.</strong> API</a></li></ol></li><li class="chapter-item expanded "><a href="indexing.html"><strong aria-hidden="true">4.</strong> Indexing</a></li><li class="chapter-item expanded "><a href="datatypes.html"><strong aria-hidden="true">5.</strong> Data Types</a></li><li class="chapter-item expanded "><a href="coming_from_pandas.html"><strong aria-hidden="true">6.</strong> Coming from Pandas</a></li><li class="chapter-item expanded "><a href="time-series.html"><strong aria-hidden="true">7.</strong> Time-series</a></li><li class="chapter-item expanded "><a href="howcani/intro.html"><strong aria-hidden="true">8.</strong> How can I?</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/io/intro.html"><strong aria-hidden="true">8.1.</strong> IO</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/io/csv.html"><strong aria-hidden="true">8.1.1.</strong> CSV files</a></li><li class="chapter-item "><a href="howcani/io/parquet.html"><strong aria-hidden="true">8.1.2.</strong> Parquet files</a></li><li class="chapter-item "><a href="howcani/io/read_db.html"><strong aria-hidden="true">8.1.3.</strong> Read from a database</a></li><li class="chapter-item "><a href="howcani/io/aws.html"><strong aria-hidden="true">8.1.4.</strong> Interact with AWS</a></li><li class="chapter-item "><a href="howcani/io/google-big-query.html"><strong aria-hidden="true">8.1.5.</strong> Interact with Google BigQuery</a></li><li class="chapter-item "><a href="howcani/io/postgres.html"><strong aria-hidden="true">8.1.6.</strong> Interact with Postgres</a></li></ol></li><li class="chapter-item "><a href="howcani/interop/intro.html"><strong aria-hidden="true">8.2.</strong> Interoperability</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/interop/arrow.html"><strong aria-hidden="true">8.2.1.</strong> Arrow</a></li><li class="chapter-item "><a href="howcani/interop/numpy.html"><strong aria-hidden="true">8.2.2.</strong> NumPy</a></li></ol></li><li class="chapter-item "><a href="howcani/data/intro.html"><strong aria-hidden="true">8.3.</strong> Data handling</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="howcani/data/strings.html"><strong aria-hidden="true">8.3.1.</strong> Process strings</a></li><li class="chapter-item "><a href="howcani/data/timestamps.html"><strong aria-hidden="true">8.3.2.</strong> Process timestamps</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="performance/intro.html"><strong aria-hidden="true">9.</strong> Performance</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="performance/strings.html"><strong aria-hidden="true">9.1.</strong> Strings</a></li></ol></li><li class="chapter-item expanded "><a href="optimizations/intro.html"><strong aria-hidden="true">10.</strong> Optimizations</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="optimizations/lazy/intro.html"><strong aria-hidden="true">10.1.</strong> Lazy API</a><a class="toggle"><div>â±</div></a></li><li><ol class="section"><li class="chapter-item "><a href="optimizations/lazy/predicate-pushdown.html"><strong aria-hidden="true">10.1.1.</strong> Predicate pushdown</a></li><li class="chapter-item "><a href="optimizations/lazy/projection-pushdown.html"><strong aria-hidden="true">10.1.2.</strong> Projection pushdown</a></li><li class="chapter-item "><a href="optimizations/lazy/other-optimizations.html"><strong aria-hidden="true">10.1.3.</strong> Other optimizations</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="references.html"><strong aria-hidden="true">11.</strong> Reference guides</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu (default)</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Polars - User Guide</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div style="margin: 30px auto; background-color: white; border-radius: 50%; width: 200px; height: 200px;"><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars-logo-dark.svg" alt="Polars logo" style="width: 168px; height: 168px; padding: 10px 20px;"></div>
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>This book is an introduction to the
<a href="https://github.com/pola-rs/polars"><code>Polars</code> DataFrame library</a>. Its goal is to
introduce you to <code>Polars</code> by going through examples and comparing it to other
solutions. Some design choices are introduced here, and the optimal use of <code>Polars</code>
described.</p>
<p>Even though <code>Polars</code> is completely written in <a href="https://www.rust-lang.org/"><code>Rust</code></a> (no
runtime overhead!) and uses <a href="https://arrow.apache.org/"><code>Arrow</code></a> -the
<a href="https://github.com/jorgecarleitao/arrow2">native arrow2 <code>Rust</code> implementation</a>- as its foundation, the
examples presented in this guide will be mostly using its higher-level language
bindings. The latter are merely a thin wrapper that will not offer more
functionalities than the core library does.</p>
<p>For people used to <a href="https://pandas.pydata.org/"><code>Pandas</code></a>, the
<a href="https://www.python.org/"><code>Python</code></a> bindings are the easiest to get started with
<code>Polars</code>, allowing easier experimentation.</p>
<h2 id="goals-and-non-goals"><a class="header" href="#goals-and-non-goals">Goals and non-goals</a></h2>
<p>The goal of <code>Polars</code> is being a lightning fast DataFrame library that utilizes all
available cores on your machine. Unlike tools like dask that tries to parallelize existing single-threaded libraries
like <code>numpy</code> and <code>pandas</code>, <code>polars</code> is written from the ground up with parallelization of DataFrame queries in mind.
It goes through great efforts to reduce redundant copies, traverse memory cache efficiently have minimal contention in
parallelism.</p>
<p><code>Polars</code> is lazy and semi-lazy. It allows you to do most of your work eagerly, similar to <code>pandas</code>, but
it does provide you with a powerful expression syntax that will be optimized and executed on polars' query engine.</p>
<p>In lazy <code>Polars</code> we are able to do query optimization on your whole queries, further improving performance and memory pressure.</p>
<p><code>Polars</code> keeps track of your query in a <em>logical plan</em>. This
plan is optimized and reordered before running it. When a result is requested <code>Polars</code>
distributes the available work to different <em>executors</em> that use the algorithms available
in the eager API to produce a result. Because the whole query context is known to
the optimizer and executors of the logical plan, processes dependent on separate data
sources can be parallelized on the fly.</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/api.svg" alt="" /></p>
<h3 id="performance-"><a class="header" href="#performance-">Performance ğŸš€ğŸš€</a></h3>
<p>Polars is very fast, and in fact is one of the best performing solutions available.
See the results in h2oai's db-benchmark. The image below shows the biggest datasets yielding a result.</p>
<p><img src="https://www.ritchievink.com/img/post-35-polars-0.15/db-benchmark.png" alt="" /></p>
<h3 id="current-status"><a class="header" href="#current-status">Current status</a></h3>
<p>Below a concise list of the features allowing <code>Polars</code> to meet its goals:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Copy-on-write">Copy-on-write</a> (COW) semantics
<ul>
<li>&quot;Free&quot; clones</li>
<li>Cheap appends</li>
</ul>
</li>
<li>Appending without clones</li>
<li>Column oriented data storage
<ul>
<li>No block manager (-i.e.- predictable performance)</li>
</ul>
</li>
<li>Missing values indicated with bitmask
<ul>
<li>NaN are different from missing</li>
<li>Bitmask optimizations</li>
</ul>
</li>
<li>Efficient algorithms</li>
<li>Very fast IO
<ul>
<li>Its csv and parquet readers are among the fastest in existence</li>
</ul>
</li>
<li><a href="optimizations/lazy/intro.html">Query optimizations</a>
<ul>
<li>Predicate pushdown
<ul>
<li>Filtering at scan level</li>
</ul>
</li>
<li>Projection pushdown
<ul>
<li>Projection at scan level</li>
</ul>
</li>
<li>Aggregate pushdown
<ul>
<li>Aggregations at scan level</li>
</ul>
</li>
<li>Simplify expressions</li>
<li>Parallel execution of physical plan</li>
<li>Cardinality based groupby dispatch
<ul>
<li>Different groupby strategies based on data cardinality</li>
</ul>
</li>
</ul>
</li>
<li>SIMD vectorization</li>
<li><a href="https://numpy.org/doc/stable/reference/ufuncs.html"><code>NumPy</code> universal functions</a></li>
</ul>
<h2 id="acknowledgements"><a class="header" href="#acknowledgements">Acknowledgements</a></h2>
<p>Development of <code>Polars</code> is proudly powered by</p>
<p><a href="https://www.xomnia.com"><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/sponsors/xomnia.png" alt="Xomnia" /></a></p>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h1>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Installing <code>Polars</code> is just a simple <code>pip install</code> away.</p>
<pre><code class="language-shell">$ pip install polars
</code></pre>
<p>All binaries are pre-built for <code>Python</code> v3.6+.</p>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick start</a></h2>
<p>Below we show a simple snippet that parses a CSV file, filters it, and finishes with a
groupby operation.</p>
<pre><code class="language-python">import polars as pl

df = pl.read_csv(&quot;https://j.mp/iriscsv&quot;)
print(df.filter(pl.col(&quot;sepal_length&quot;) &gt; 5)
      .groupby(&quot;species&quot;)
      .agg(pl.all().sum())
)
</code></pre>
<p>The snippet above will output:</p>
<pre><code class="language-text">shape: (3, 5)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ species      â”† sepal_length_sum â”† sepal_width_sum â”† petal_length_sum â”† petal_width_sum â”‚
â”‚ ---          â”† ---              â”† ---             â”† ---              â”† ---             â”‚
â”‚ str          â”† f64              â”† f64             â”† f64              â”† f64             â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ &quot;virginica&quot;  â”† 324.5            â”† 146.2           â”† 273.1            â”† 99.6            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ &quot;versicolor&quot; â”† 281.9            â”† 131.8           â”† 202.9            â”† 63.3            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ &quot;setosa&quot;     â”† 116.9            â”† 81.7            â”† 33.2             â”† 6.1             â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
</code></pre>
<p>As we can see, <code>Polars</code> pretty-prints the output object, including the column name and
datatype as headers.</p>
<h2 id="lazy-quick-start"><a class="header" href="#lazy-quick-start">Lazy quick start</a></h2>
<p>If we want to run this query in <code>lazy polars</code> we'd write:</p>
<pre><code class="language-python">import polars as pl

print(
    pl.read_csv(&quot;https://j.mp/iriscsv&quot;)
    .lazy()
    .filter(pl.col(&quot;sepal_length&quot;) &gt; 5)
    .groupby(&quot;species&quot;)
    .agg(pl.all().sum())
    .collect()
)
</code></pre>
<p>When the data is not stored on the internet, we can also use <code>scan_csv</code> to run the query in lazy polars.</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<p>If you want to dive right into the <code>Python</code> API docs, check the <a href="https://pola-rs.github.io/polars/py-polars/html/reference">the index</a>.</p>
<h3 id="lazy-api"><a class="header" href="#lazy-api">Lazy API</a></h3>
<p>The lazy API builds a query plan. Nothing is executed until you explicitly ask <code>Polars</code>
to execute the query (via <code>LazyFrame.collect()</code>, or <code>LazyFrame.fetch()</code>). This provides
<code>Polars</code> with the entire context of the query, allowing optimizations and choosing the
fastest algorithm given that context.</p>
<p>Going from eager to lazy is often as simple as starting your query with <code>.lazy()</code> and ending with <code>.collect()</code>.</p>
<p>So the eager snippet above would become:</p>
<pre><code class="language-python">(
    df.lazy()
    .filter(pl.col(&quot;sepal_length&quot;) &gt; 5)
    .groupby(&quot;species&quot;)
    .agg(pl.all().sum())
    .collect()
)
</code></pre>
<h1 id="polars-expressions"><a class="header" href="#polars-expressions">Polars Expressions</a></h1>
<p>Polars has a powerful concept called expressions. Polars expressions can be used in
various contexts and are a functional mapping of <code>Fn(Series) -&gt; Series</code>, meaning that they have <code>Series</code> as input and
<code>Series</code> as output. By looking at this functional definition, we can see that the output of an <code>Expr</code> also can serve
as the input of an <code>Expr</code>.</p>
<p>That may sound a bit strange, so lets give an
example.</p>
<p>The following is an expression:</p>
<p><code>pl.col(&quot;foo&quot;).sort().head(2)</code></p>
<p>The snippet above says <code>select column &quot;foo&quot; then sort this column and then take first 2 values of the sorted output</code>. The
power of expressions is that every expression produces a new expression and that they
can be <code>piped</code> together. You can run an expression by passing them on one of polars execution contexts. Here we run
two expressions by running <code>df.select</code>:</p>
<pre><code class="language-python">df.select([
    pl.col(&quot;foo&quot;).sort().head(2),
    pl.col(&quot;bar&quot;).filter(pl.col(&quot;foo&quot;) == 1).sum()
])
</code></pre>
<p>All expressions are ran in parallel, meaning that separate polars expressions are <strong>embarrassingly
parallel</strong>. (Note that within an expression there may be more parallelization going on).</p>
<h2 id="expression-examples"><a class="header" href="#expression-examples">Expression examples</a></h2>
<p>In this section we will go through some examples, but first let's create a dataset:</p>
<pre><code class="language-python">import polars as pl
import numpy as np

np.random.seed(12)

df = pl.DataFrame(
    {
        &quot;nrs&quot;: [1, 2, 3, None, 5],
        &quot;names&quot;: [&quot;foo&quot;, &quot;ham&quot;, &quot;spam&quot;, &quot;egg&quot;, None],
        &quot;random&quot;: np.random.rand(5),
        &quot;groups&quot;: [&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;],
    }
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ nrs  â”† names â”† random   â”† groups â”‚
â”‚ ---  â”† ---   â”† ---      â”† ---    â”‚
â”‚ i64  â”† str   â”† f64      â”† str    â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ 1    â”† foo   â”† 0.154163 â”† A      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2    â”† ham   â”† 0.74     â”† A      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3    â”† spam  â”† 0.263315 â”† B      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ null â”† egg   â”† 0.533739 â”† C      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 5    â”† null  â”† 0.014575 â”† B      â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>You can do a lot with expressions. They are so expressive that you sometimes have
multiple ways to get the same results. To get a feel for them let's go through some
examples.</p>
<h3 id="count-unique-values"><a class="header" href="#count-unique-values">Count unique values</a></h3>
<p>We can count the unique values in a column. Note that we are creating the same result in
different ways. To not have duplicate column names in the <code>DataFrame</code>, we use an
<code>alias</code> expression, which renames an expression.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.col(&quot;names&quot;).n_unique().alias(&quot;unique_names_1&quot;),
        pl.col(&quot;names&quot;).unique().count().alias(&quot;unique_names_2&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ unique_names_1 â”† unique_names_2 â”‚
â”‚ ---            â”† ---            â”‚
â”‚ u32            â”† u32            â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 5              â”† 5              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="various-aggregations"><a class="header" href="#various-aggregations">Various aggregations</a></h3>
<p>We can do various aggregations. Below we show some of them, but there are more, such as
<code>median</code>, <code>mean</code>, <code>first</code>, etc.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.sum(&quot;random&quot;).alias(&quot;sum&quot;),
        pl.min(&quot;random&quot;).alias(&quot;min&quot;),
        pl.max(&quot;random&quot;).alias(&quot;max&quot;),
        pl.col(&quot;random&quot;).max().alias(&quot;other_max&quot;),
        pl.std(&quot;random&quot;).alias(&quot;std dev&quot;),
        pl.var(&quot;random&quot;).alias(&quot;variance&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sum      â”† min      â”† max  â”† other_max â”† std dev  â”† variance â”‚
â”‚ ---      â”† ---      â”† ---  â”† ---       â”† ---      â”† ---      â”‚
â”‚ f64      â”† f64      â”† f64  â”† f64       â”† f64      â”† f64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1.705842 â”† 0.014575 â”† 0.74 â”† 0.74      â”† 0.293209 â”† 0.085971 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="filter-and-conditionals"><a class="header" href="#filter-and-conditionals">Filter and conditionals</a></h3>
<p>We can also do some pretty complex things. In the next snippet we count all names ending
with the string <code>&quot;am&quot;</code>.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.col(&quot;names&quot;).filter(pl.col(&quot;names&quot;).str.contains(r&quot;am$&quot;)).count(),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (1, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚ names â”‚
â”‚ ---   â”‚
â”‚ u32   â”‚
â•â•â•â•â•â•â•â•â•¡
â”‚ 2     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="binary-functions-and-modification"><a class="header" href="#binary-functions-and-modification">Binary functions and modification</a></h3>
<p>In the example below we use a conditional to create a new expression in the following
<code>when -&gt; then -&gt; otherwise</code> construct. The <code>when()</code> function requires a predicate
expression (and thus leads to a <code>boolean</code> <code>Series</code>), the <code>then</code> expects an
expression that will be used in case the predicate evaluates <code>true</code>, and the <code>otherwise</code>
expects an expression that will be used in case the predicate evaluates <code>false</code>.</p>
<p>Note that you can pass any expression, or just base expressions like <code>pl.col(&quot;foo&quot;)</code>,
<code>pl.lit(3)</code>, <code>pl.lit(&quot;bar&quot;)</code>, etc.</p>
<p>Finally, we multiply this with result of a sum expression.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.when(pl.col(&quot;random&quot;) &gt; 0.5).then(0).otherwise(pl.col(&quot;random&quot;)) * pl.sum(&quot;nrs&quot;),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ literal  â”‚
â”‚ ---      â”‚
â”‚ f64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1.695791 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.0      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2.896465 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.0      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.160325 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="window-expressions"><a class="header" href="#window-expressions">Window expressions</a></h3>
<p>A polars expression can also do an implicit GROUPBY, AGGREGATION, and JOIN in a single expression.
In the examples below we do a GROUPBY OVER <code>&quot;groups&quot;</code> and AGGREGATE SUM of <code>&quot;random&quot;</code>, and in the next expression
we GROUPBY OVER <code>&quot;names&quot;</code> and AGGREGATE a LIST of <code>&quot;random&quot;</code>. These window functions can be combined with other expressions,
and are an efficient way to determine group statistics. See more of those <a href="https://pola-rs.github.io/polars/py-polars/html/reference/expression.html#aggregation">group statistics here</a>.</p>
<pre><code class="language-python">df = df[
    [
        pl.col(&quot;*&quot;),  # select all
        pl.col(&quot;random&quot;).sum().over(&quot;groups&quot;).alias(&quot;sum[random]/groups&quot;),
        pl.col(&quot;random&quot;).list().over(&quot;names&quot;).alias(&quot;random/name&quot;),
    ]
]
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ nrs  â”† names â”† random   â”† groups â”† sum[random]/groups â”† random/name â”‚
â”‚ ---  â”† ---   â”† ---      â”† ---    â”† ---                â”† ---         â”‚
â”‚ i64  â”† str   â”† f64      â”† str    â”† f64                â”† list [f64]  â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1    â”† foo   â”† 0.154163 â”† A      â”† 0.894213           â”† [0.154163]  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2    â”† ham   â”† 0.74     â”† A      â”† 0.894213           â”† [0.74]      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3    â”† spam  â”† 0.263315 â”† B      â”† 0.2778             â”† [0.263315]  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ null â”† egg   â”† 0.533739 â”† C      â”† 0.533739           â”† [0.533739]  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 5    â”† null  â”† 0.014575 â”† B      â”† 0.2778             â”† [0.014575]  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>This is the tip of the iceberg in terms of possible expressions, there are a ton more, and they
can be combined in myriad ways.</p>
<p>This page was an introduction to Polars expressions and gave a glimpse of what's
possible with them. In the next page, we see in which contexts we can use expressions. And later we'll go through expressions
in various groupby contexts and by doing that keep Polars execution parallel.</p>
<h1 id="polars-expressions-1"><a class="header" href="#polars-expressions-1">Polars Expressions</a></h1>
<p>Polars has a powerful concept called expressions. Polars expressions can be used in
various contexts and are a functional mapping of <code>Fn(Series) -&gt; Series</code>, meaning that they have <code>Series</code> as input and
<code>Series</code> as output. By looking at this functional definition, we can see that the output of an <code>Expr</code> also can serve
as the input of an <code>Expr</code>.</p>
<p>That may sound a bit strange, so lets give an
example.</p>
<p>The following is an expression:</p>
<p><code>pl.col(&quot;foo&quot;).sort().head(2)</code></p>
<p>The snippet above says <code>select column &quot;foo&quot; then sort this column and then take first 2 values of the sorted output</code>. The
power of expressions is that every expression produces a new expression and that they
can be <code>piped</code> together. You can run an expression by passing them on one of polars execution contexts. Here we run
two expressions by running <code>df.select</code>:</p>
<pre><code class="language-python">df.select([
    pl.col(&quot;foo&quot;).sort().head(2),
    pl.col(&quot;bar&quot;).filter(pl.col(&quot;foo&quot;) == 1).sum()
])
</code></pre>
<p>All expressions are ran in parallel, meaning that separate polars expressions are <strong>embarrassingly
parallel</strong>. (Note that within an expression there may be more parallelization going on).</p>
<h2 id="expression-examples-1"><a class="header" href="#expression-examples-1">Expression examples</a></h2>
<p>In this section we will go through some examples, but first let's create a dataset:</p>
<pre><code class="language-python">import polars as pl
import numpy as np

np.random.seed(12)

df = pl.DataFrame(
    {
        &quot;nrs&quot;: [1, 2, 3, None, 5],
        &quot;names&quot;: [&quot;foo&quot;, &quot;ham&quot;, &quot;spam&quot;, &quot;egg&quot;, None],
        &quot;random&quot;: np.random.rand(5),
        &quot;groups&quot;: [&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;],
    }
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ nrs  â”† names â”† random   â”† groups â”‚
â”‚ ---  â”† ---   â”† ---      â”† ---    â”‚
â”‚ i64  â”† str   â”† f64      â”† str    â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ 1    â”† foo   â”† 0.154163 â”† A      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2    â”† ham   â”† 0.74     â”† A      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3    â”† spam  â”† 0.263315 â”† B      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ null â”† egg   â”† 0.533739 â”† C      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 5    â”† null  â”† 0.014575 â”† B      â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>You can do a lot with expressions. They are so expressive that you sometimes have
multiple ways to get the same results. To get a feel for them let's go through some
examples.</p>
<h3 id="count-unique-values-1"><a class="header" href="#count-unique-values-1">Count unique values</a></h3>
<p>We can count the unique values in a column. Note that we are creating the same result in
different ways. To not have duplicate column names in the <code>DataFrame</code>, we use an
<code>alias</code> expression, which renames an expression.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.col(&quot;names&quot;).n_unique().alias(&quot;unique_names_1&quot;),
        pl.col(&quot;names&quot;).unique().count().alias(&quot;unique_names_2&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ unique_names_1 â”† unique_names_2 â”‚
â”‚ ---            â”† ---            â”‚
â”‚ u32            â”† u32            â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 5              â”† 5              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="various-aggregations-1"><a class="header" href="#various-aggregations-1">Various aggregations</a></h3>
<p>We can do various aggregations. Below we show some of them, but there are more, such as
<code>median</code>, <code>mean</code>, <code>first</code>, etc.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.sum(&quot;random&quot;).alias(&quot;sum&quot;),
        pl.min(&quot;random&quot;).alias(&quot;min&quot;),
        pl.max(&quot;random&quot;).alias(&quot;max&quot;),
        pl.col(&quot;random&quot;).max().alias(&quot;other_max&quot;),
        pl.std(&quot;random&quot;).alias(&quot;std dev&quot;),
        pl.var(&quot;random&quot;).alias(&quot;variance&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sum      â”† min      â”† max  â”† other_max â”† std dev  â”† variance â”‚
â”‚ ---      â”† ---      â”† ---  â”† ---       â”† ---      â”† ---      â”‚
â”‚ f64      â”† f64      â”† f64  â”† f64       â”† f64      â”† f64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1.705842 â”† 0.014575 â”† 0.74 â”† 0.74      â”† 0.293209 â”† 0.085971 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="filter-and-conditionals-1"><a class="header" href="#filter-and-conditionals-1">Filter and conditionals</a></h3>
<p>We can also do some pretty complex things. In the next snippet we count all names ending
with the string <code>&quot;am&quot;</code>.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.col(&quot;names&quot;).filter(pl.col(&quot;names&quot;).str.contains(r&quot;am$&quot;)).count(),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (1, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚ names â”‚
â”‚ ---   â”‚
â”‚ u32   â”‚
â•â•â•â•â•â•â•â•â•¡
â”‚ 2     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="binary-functions-and-modification-1"><a class="header" href="#binary-functions-and-modification-1">Binary functions and modification</a></h3>
<p>In the example below we use a conditional to create a new expression in the following
<code>when -&gt; then -&gt; otherwise</code> construct. The <code>when()</code> function requires a predicate
expression (and thus leads to a <code>boolean</code> <code>Series</code>), the <code>then</code> expects an
expression that will be used in case the predicate evaluates <code>true</code>, and the <code>otherwise</code>
expects an expression that will be used in case the predicate evaluates <code>false</code>.</p>
<p>Note that you can pass any expression, or just base expressions like <code>pl.col(&quot;foo&quot;)</code>,
<code>pl.lit(3)</code>, <code>pl.lit(&quot;bar&quot;)</code>, etc.</p>
<p>Finally, we multiply this with result of a sum expression.</p>
<pre><code class="language-python">out = df.select(
    [
        pl.when(pl.col(&quot;random&quot;) &gt; 0.5).then(0).otherwise(pl.col(&quot;random&quot;)) * pl.sum(&quot;nrs&quot;),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ literal  â”‚
â”‚ ---      â”‚
â”‚ f64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1.695791 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.0      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2.896465 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.0      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.160325 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="window-expressions-1"><a class="header" href="#window-expressions-1">Window expressions</a></h3>
<p>A polars expression can also do an implicit GROUPBY, AGGREGATION, and JOIN in a single expression.
In the examples below we do a GROUPBY OVER <code>&quot;groups&quot;</code> and AGGREGATE SUM of <code>&quot;random&quot;</code>, and in the next expression
we GROUPBY OVER <code>&quot;names&quot;</code> and AGGREGATE a LIST of <code>&quot;random&quot;</code>. These window functions can be combined with other expressions,
and are an efficient way to determine group statistics. See more of those <a href="https://pola-rs.github.io/polars/py-polars/html/reference/expression.html#aggregation">group statistics here</a>.</p>
<pre><code class="language-python">df = df[
    [
        pl.col(&quot;*&quot;),  # select all
        pl.col(&quot;random&quot;).sum().over(&quot;groups&quot;).alias(&quot;sum[random]/groups&quot;),
        pl.col(&quot;random&quot;).list().over(&quot;names&quot;).alias(&quot;random/name&quot;),
    ]
]
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ nrs  â”† names â”† random   â”† groups â”† sum[random]/groups â”† random/name â”‚
â”‚ ---  â”† ---   â”† ---      â”† ---    â”† ---                â”† ---         â”‚
â”‚ i64  â”† str   â”† f64      â”† str    â”† f64                â”† list [f64]  â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1    â”† foo   â”† 0.154163 â”† A      â”† 0.894213           â”† [0.154163]  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2    â”† ham   â”† 0.74     â”† A      â”† 0.894213           â”† [0.74]      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3    â”† spam  â”† 0.263315 â”† B      â”† 0.2778             â”† [0.263315]  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ null â”† egg   â”† 0.533739 â”† C      â”† 0.533739           â”† [0.533739]  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 5    â”† null  â”† 0.014575 â”† B      â”† 0.2778             â”† [0.014575]  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>This is the tip of the iceberg in terms of possible expressions, there are a ton more, and they
can be combined in myriad ways.</p>
<p>This page was an introduction to Polars expressions and gave a glimpse of what's
possible with them. In the next page, we see in which contexts we can use expressions. And later we'll go through expressions
in various groupby contexts and by doing that keep Polars execution parallel.</p>
<h1 id="expression-contexts"><a class="header" href="#expression-contexts">Expression contexts</a></h1>
<p>You cannot use an expression anywhere. An expression needs a context, the available contexts are:</p>
<ul>
<li>selection: <code>df.select([..])</code></li>
<li>groupy aggregation: <code>df.groupby(..).agg([..])</code></li>
<li>hstack/ add columns: <code>df.with_columns([..])</code></li>
</ul>
<h2 id="syntactic-sugar"><a class="header" href="#syntactic-sugar">Syntactic sugar</a></h2>
<p>The reason for such a context, is that you actually are using the Polars lazy API, even if you use it in eager.
For instance this snippet:</p>
<pre><code class="language-python">df.groupby(&quot;foo&quot;).agg([pl.col(&quot;bar&quot;).sum()])
</code></pre>
<p>actually desugars to:</p>
<pre><code class="language-python">(df.lazy().groupby(&quot;foo&quot;).agg([pl.col(&quot;bar&quot;).sum()])).collect()
</code></pre>
<p>This allows Polars to push the expression into the query engine, do optimizations, and cache intermediate results.</p>
<h2 id="select-context"><a class="header" href="#select-context">Select context</a></h2>
<p>You cannot use an expression everywhere. An expression needs a context from which it can
select the column <code>&quot;foo&quot;</code> to start with.</p>
<h4 id="selection-context"><a class="header" href="#selection-context">Selection context</a></h4>
<pre><code class="language-python">df = df.select(
    [
        pl.sum(&quot;nrs&quot;),
        pl.col(&quot;names&quot;).sort(),
    ]
)
</code></pre>
<h2 id="groupby-context"><a class="header" href="#groupby-context">Groupby context</a></h2>
<p>You can use expression during <code>groupby</code> aggregations:</p>
<pre><code class="language-python">df = df.groupby(&quot;groups&quot;).agg(
    [
        pl.sum(&quot;nrs&quot;),
        pl.col(&quot;random&quot;).count().alias(&quot;count&quot;),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (3, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ groups â”† nrs_sum â”† count â”‚
â”‚ ---    â”† ---     â”† ---   â”‚
â”‚ str    â”† i64     â”† u32   â”‚
â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ B      â”† 8       â”† 2     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ A      â”† 3       â”† 2     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ C      â”† null    â”† 1     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="add-columns-context"><a class="header" href="#add-columns-context">Add columns context</a></h2>
<p>And finally you can use expressions to add one or multiple columns to an existing <code>DataFrame</code></p>
<pre><code class="language-python">df = df.with_columns(
    [
        pl.sum(&quot;nrs&quot;).alias(&quot;nrs_sum&quot;),
        pl.col(&quot;random&quot;).count().alias(&quot;count&quot;),
    ]
)
print(df)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ nrs  â”† names â”† random   â”† groups â”† nrs_sum â”† count â”‚
â”‚ ---  â”† ---   â”† ---      â”† ---    â”† ---     â”† ---   â”‚
â”‚ i64  â”† str   â”† f64      â”† str    â”† i64     â”† u32   â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ 1    â”† foo   â”† 0.154163 â”† A      â”† 11      â”† 5     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2    â”† ham   â”† 0.74     â”† A      â”† 11      â”† 5     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3    â”† spam  â”† 0.263315 â”† B      â”† 11      â”† 5     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ null â”† egg   â”† 0.533739 â”† C      â”† 11      â”† 5     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 5    â”† null  â”† 0.014575 â”† B      â”† 11      â”† 5     â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h1 id="groupby"><a class="header" href="#groupby">GroupBy</a></h1>
<blockquote>
<p>In redaction</p>
</blockquote>
<h2 id="a-multithreaded-approach"><a class="header" href="#a-multithreaded-approach">A multithreaded approach</a></h2>
<p>One of the most efficient way to process tabular data is to parallelize its processing
via the &quot;split-apply-combine&quot; approach. This operation is at the core of <code>Polars</code>
grouping implementation, allowing it to attain lightning-fast operations. Most
specifically, both the &quot;split&quot; and &quot;apply&quot; phases are executed in a multi-threaded
fashion.</p>
<p>A simple grouping operation is taken below as an example to illustrate this approach:</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/split-apply-combine.svg" alt="" /></p>
<p>For the hashing operations performed during the &quot;split&quot; phase, <code>Polars</code> uses a
multithreaded lock-free approach that is illustrated on the following schema:</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/lock-free-hash.svg" alt="" /></p>
<p>This parallelization allows the grouping and joining operations (for instance) to be
blazingly fast!</p>
<blockquote>
<p>Include content from the
<a href="https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/">blog post</a></p>
</blockquote>
<h2 id="do-not-kill-the-parallelization"><a class="header" href="#do-not-kill-the-parallelization">Do not kill the parallelization!</a></h2>
<p>We have all heard that <code>Python</code> is slow, and does &quot;not scale.&quot; Besides the overhead of
running &quot;slow&quot; bytecode, <code>Python</code> has to remain within the constraints of the Global
Interpreter Lock (GIL). This means that if one uses a <code>lambda</code> or a custom <code>Python</code>
function to apply during a parallelized phase, <code>Polars</code> speed is capped running <code>Python</code>
code preventing any multiple threads from executing the function.</p>
<p>This all feels terribly limiting, especially because we often need those <code>lambda</code> in a
<code>.groupby()</code> step for instance. This approach is still supported by <code>Polars</code>, but
keeping in mind bytecode AND the GIL price have to be paid.</p>
<p>To mitigate this, <code>Polars</code> implements a powerful syntax defined not only in its lazy,
but also in its eager API.</p>
<h2 id="polars-expressions-2"><a class="header" href="#polars-expressions-2">Polars Expressions</a></h2>
<p>In the introduction on previous page we discussed that using custom Python functions,
killed parallelization, and that we can use the expressions of the lazy API to mitigate
this. Let's take a look at what that means.</p>
<p>Let's start with the simple
<a href="https://github.com/unitedstates/congress-legislators">US congress dataset</a>.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby(&quot;first_name&quot;)
    .agg(
        [
            pl.count(&quot;party&quot;),
            pl.col(&quot;gender&quot;).list(),
            pl.first(&quot;last_name&quot;),
        ]
    )
    .sort(&quot;party_count&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<h4 id="basic-aggregations"><a class="header" href="#basic-aggregations">Basic aggregations</a></h4>
<p>You can easily combine different aggregations by adding multiple expressions in a
<code>list</code>. There is no upper bound on the number of aggregations you can do, and you can
make any combination you want. In the snippet below we do the following aggregations:</p>
<p>Per GROUP <code>&quot;first_name&quot;</code> we</p>
<ul>
<li>count the number of rows in the group:
<ul>
<li>short form: <code>pl.count(&quot;party&quot;)</code></li>
<li>full form: <code>pl.col(&quot;party&quot;).count()</code></li>
</ul>
</li>
<li>aggregate the gender values group to a list:
<ul>
<li>full form: <code>pl.col(&quot;gender&quot;).list()</code></li>
</ul>
</li>
<li>get the first value of column <code>&quot;last_name&quot;</code> in the group:
<ul>
<li>short form: <code>pl.first(&quot;last_name&quot;)</code></li>
<li>full form: <code>pl.col(&quot;last_name&quot;).first()</code></li>
</ul>
</li>
</ul>
<p>Besides the aggregation, we immediately sort the result and limit to the top 5 so that
we have a nice summary overview.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby(&quot;first_name&quot;)
    .agg(
        [
            pl.count(&quot;party&quot;),
            pl.col(&quot;gender&quot;).list(),
            pl.first(&quot;last_name&quot;),
        ]
    )
    .sort(&quot;party_count&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ first_name â”† party_count â”† gender_agg_list     â”† last_name_first â”‚
â”‚ ---        â”† ---         â”† ---                 â”† ---             â”‚
â”‚ cat        â”† u32         â”† list [cat]          â”† str             â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ John       â”† 1254        â”† [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] â”† Walker          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ William    â”† 1022        â”† [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] â”† Few             â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ James      â”† 712         â”† [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] â”† Armstrong       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Thomas     â”† 453         â”† [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] â”† Tucker          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Charles    â”† 439         â”† [&quot;M&quot;, &quot;M&quot;, ... &quot;M&quot;] â”† Carroll         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="conditionals"><a class="header" href="#conditionals">Conditionals</a></h4>
<p>Ok, that was pretty easy right. Let's turn it up a notch. Let's say we want to know how
many delegates of a &quot;state&quot; are &quot;Pro&quot; or &quot;Anti&quot; administration we could directly query
that in the aggregation without the need of <code>lambda</code> or grooming the DataFrame.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby(&quot;state&quot;)
    .agg(
        [
            (pl.col(&quot;party&quot;) == &quot;Anti-Administration&quot;).sum().alias(&quot;anti&quot;),
            (pl.col(&quot;party&quot;) == &quot;Pro-Administration&quot;).sum().alias(&quot;pro&quot;),
        ]
    )
    .sort(&quot;pro&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ state â”† anti â”† pro â”‚
â”‚ ---   â”† ---  â”† --- â”‚
â”‚ cat   â”† u32  â”† u32 â”‚
â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡
â”‚ NJ    â”† 0    â”† 3   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ CT    â”† 0    â”† 3   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ NC    â”† 1    â”† 2   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ PA    â”† 1    â”† 1   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ SC    â”† 0    â”† 1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Something similar could of course also be done with a nested GROUPBY, but that would not
allow me showing these nice features. ğŸ˜‰</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset

q = (
    dataset.lazy()
    .groupby([&quot;state&quot;, &quot;party&quot;])
    .agg([pl.count(&quot;party&quot;).alias(&quot;count&quot;)])
    .filter((pl.col(&quot;party&quot;) == &quot;Anti-Administration&quot;) | (pl.col(&quot;party&quot;) == &quot;Pro-Administration&quot;))
    .sort(&quot;count&quot;, reverse=True)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ state â”† party               â”† count â”‚
â”‚ ---   â”† ---                 â”† ---   â”‚
â”‚ cat   â”† cat                 â”† u32   â”‚
â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ NJ    â”† Pro-Administration  â”† 3     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ CT    â”† Pro-Administration  â”† 3     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ VA    â”† Anti-Administration â”† 3     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ NC    â”† Pro-Administration  â”† 2     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ DE    â”† Anti-Administration â”† 1     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="filtering"><a class="header" href="#filtering">Filtering</a></h4>
<p>We can also filter the groups. Let's say we want to compute a mean per group, but we
don't want to include all values from that group and we also don't want to filter the
rows from the <code>DataFrame</code> (because we need that rows for another aggregation.)</p>
<p>In the example below we show how that can be done. Note that we can make <code>Python</code>
functions for clarity. These functions don't cost us anything. That is because we only
create <code>Polars</code> expression, we don't apply a custom function over <code>Series</code> during
runtime of the query.</p>
<pre><code class="language-python">from datetime import date

import polars as pl

from .dataset import dataset


def compute_age() -&gt; pl.Expr:
    return date(2021, 1, 1).year - pl.col(&quot;birthday&quot;).dt.year()


def avg_birthday(gender: str) -&gt; pl.Expr:
    return compute_age().filter(pl.col(&quot;gender&quot;) == gender).mean().alias(f&quot;avg {gender} birthday&quot;)


q = (
    dataset.lazy()
    .groupby([&quot;state&quot;])
    .agg(
        [
            avg_birthday(&quot;M&quot;),
            avg_birthday(&quot;F&quot;),
            (pl.col(&quot;gender&quot;) == &quot;M&quot;).sum().alias(&quot;# male&quot;),
            (pl.col(&quot;gender&quot;) == &quot;F&quot;).sum().alias(&quot;# female&quot;),
        ]
    )
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 5)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ state â”† avg M birthday â”† avg F birthday â”† # male â”† # female â”‚
â”‚ ---   â”† ---            â”† ---            â”† ---    â”† ---      â”‚
â”‚ cat   â”† f64            â”† f64            â”† u32    â”† u32      â”‚
â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
â”‚ FL    â”† 116.4375       â”† 77.857143      â”† 147    â”† 14       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ DK    â”† 191.333333     â”† null           â”† 9      â”† 0        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ SC    â”† 183.5668       â”† 121.8          â”† 246    â”† 5        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ WY    â”† 137.717949     â”† 75.0           â”† 39     â”† 1        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ NJ    â”† 174.991124     â”† 112.0          â”† 354    â”† 5        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4 id="sorting"><a class="header" href="#sorting">Sorting</a></h4>
<p>I often see a DataFrame being sorted for the sole purpose of the ordering during the
GROUPBY operation. Let's say that we want to get the names of the oldest and youngest
(not that they are still alive) politicians per state, we could SORT and GROUPBY.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset


def get_person() -&gt; pl.Expr:
    return pl.col(&quot;first_name&quot;) + pl.lit(&quot; &quot;) + pl.col(&quot;last_name&quot;)


q = (
    dataset.lazy()
    .sort(&quot;birthday&quot;)
    .groupby([&quot;state&quot;])
    .agg(
        [
            get_person().first().alias(&quot;youngest&quot;),
            get_person().last().alias(&quot;oldest&quot;),
        ]
    )
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ state â”† youngest           â”† oldest         â”‚
â”‚ ---   â”† ---                â”† ---            â”‚
â”‚ cat   â”† str                â”† str            â”‚
â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ FL    â”† Charles Downing    â”† Patrick Murphy â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ WY    â”† Stephen Nuckolls   â”† Barbara Cubin  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ DE    â”† Samuel White       â”† John Carney    â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ CO    â”† Allen Bradford     â”† Jared Polis    â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ NJ    â”† Lambert Cadwalader â”† Jon Runyan     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>However, IF we also want to sort the names alphabetically (and why wouldn't you!), this
breaks. Luckily we can sort in a groupby context separate from the <code>DataFrame</code>.</p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset


def get_person() -&gt; pl.Expr:
    return pl.col(&quot;first_name&quot;) + pl.lit(&quot; &quot;) + pl.col(&quot;last_name&quot;)


q = (
    dataset.lazy()
    .sort(&quot;birthday&quot;)
    .groupby([&quot;state&quot;])
    .agg(
        [
            get_person().first().alias(&quot;youngest&quot;),
            get_person().last().alias(&quot;oldest&quot;),
            get_person().sort().first().alias(&quot;alphabetical_first&quot;),
        ]
    )
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ state â”† youngest              â”† oldest         â”† alphabetical_first â”‚
â”‚ ---   â”† ---                   â”† ---            â”† ---                â”‚
â”‚ cat   â”† str                   â”† str            â”† str                â”‚
â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ OH    â”† John Smith            â”† John Boccieri  â”† Aaron Harlan       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ ID    â”† William Wallace       â”† RaÃºl Labrador  â”† Abe Goff           â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ DK    â”† John Todd             â”† George Mathews â”† George Mathews     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ SC    â”† Ralph Izard           â”† Joe Cunningham â”† Abraham Nott       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ NY    â”† Cornelius Schoonmaker â”† Max Rose       â”† A. Foster          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>We can even sort by another column in the GROUPBY context. If we want to know if the
alphabetically sorted name is male or female we could add
<code>pl.col(&quot;gender&quot;).sort_by(&quot;first_name&quot;).first().alias(&quot;gender&quot;)</code></p>
<pre><code class="language-python">import polars as pl

from .dataset import dataset


def get_person() -&gt; pl.Expr:
    return pl.col(&quot;first_name&quot;) + pl.lit(&quot; &quot;) + pl.col(&quot;last_name&quot;)


q = (
    dataset.lazy()
    .sort(&quot;birthday&quot;)
    .groupby([&quot;state&quot;])
    .agg(
        [
            get_person().first().alias(&quot;youngest&quot;),
            get_person().last().alias(&quot;oldest&quot;),
            get_person().sort().first().alias(&quot;alphabetical_first&quot;),
            pl.col(&quot;gender&quot;).sort_by(&quot;first_name&quot;).first().alias(&quot;gender&quot;),
        ]
    )
    .sort(&quot;state&quot;)
    .limit(5)
)

df = q.collect()
</code></pre>
<pre><code class="language-text">shape: (5, 5)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ state â”† youngest       â”† oldest           â”† alphabetical_first â”† gender â”‚
â”‚ ---   â”† ---            â”† ---              â”† ---                â”† ---    â”‚
â”‚ cat   â”† str            â”† str              â”† str                â”† cat    â”‚
â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ AK    â”† Thomas Cale    â”† Mark Begich      â”† Anthony Dimond     â”† M      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ AL    â”† John McKee     â”† Martha Roby      â”† Albert Goodwyn     â”† M      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ AR    â”† Archibald Yell â”† Tim Griffin      â”† Albert Rust        â”† M      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ AS    â”† FofÃ³ Sunia     â”† Eni Faleomavaega â”† Eni Faleomavaega   â”† M      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ AZ    â”† Coles Bashford â”† Ben Quayle       â”† Barry Goldwater    â”† M      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="conclusion-2"><a class="header" href="#conclusion-2">Conclusion</a></h3>
<p>In the examples above we've seen that we can do a lot by combining expressions. By doing
so we delay the use of custom python functions that slow down the queries (by the slow
nature of Python AND the GIL).</p>
<p>If you think there is a type expression missing, let me know and open a
<a href="https://github.com/pola-rs/polars/issues/new/choose">feature request</a>.</p>
<h1 id="folds"><a class="header" href="#folds">Folds</a></h1>
<p>Polars provides expressions/methods for horizontal aggregations like, <a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.sum.html">sum</a>,
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.min.html">min</a>, <a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.mean.html">mean</a>,
etc. by setting the argument <code>axis=1</code>. However, when you need a more complex aggregation the default ones provided by the
polars library may not be sufficient. That's when <code>folds</code> come in handy. Polars' <code>fold</code> expression operates on columns and
can therefore be really fast. It utilizes the data layout most efficiently and often has vectorized execution.</p>
<p>Let's start with an example by implement the <code>sum</code> operation ourselves, with a <code>fold</code></p>
<h2 id="manual-sum"><a class="header" href="#manual-sum">Manual Sum</a></h2>
<pre><code class="language-python">
out = df.select(
    pl.fold(acc=pl.lit(0), f=lambda acc, x: acc + x, exprs=pl.col(&quot;*&quot;)).alias(&quot;sum&quot;),
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 1)
â”Œâ”€â”€â”€â”€â”€â”
â”‚ sum â”‚
â”‚ --- â”‚
â”‚ i64 â”‚
â•â•â•â•â•â•â•¡
â”‚ 11  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 22  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 33  â”‚
â””â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>The snippet above recursively applies the function <code>f(acc, x) -&gt; acc</code> to an accumulator <code>acc</code> and a new column <code>x</code>.
The function operations on columns at a time and can take advantage from cache efficiency and vectorization.</p>
<h2 id="conditional"><a class="header" href="#conditional">Conditional</a></h2>
<p>In the case where you'd want to apply a condition/predicate on all columns in a <code>DataFrame</code> a <code>fold</code> operation can be
a very concise way to express this.</p>
<pre><code class="language-python">
out = df.filter(
    pl.fold(
        acc=pl.lit(True),
        f=lambda acc, x: acc &amp; x,
        exprs=pl.col(&quot;*&quot;) &gt; 1,
    )
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (1, 2)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ a   â”† b   â”‚
â”‚ --- â”† --- â”‚
â”‚ i64 â”† i64 â”‚
â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡
â”‚ 3   â”† 2   â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>In the snippet we filter all rows that have <strong>ALL</strong> values &gt; 1.</p>
<h2 id="folds-and-string-data"><a class="header" href="#folds-and-string-data">Folds and string data</a></h2>
<p>Folds could be used to concatenate string data. However, due to the materialization of intermediate columns, this
operation will have squared complexity.</p>
<p>Therefore, we recommend using the <code>concat_str</code> expression for this.</p>
<pre><code class="language-python">df = pl.DataFrame({&quot;a&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;b&quot;: [1, 2, 3]})

out = df.select(
    [
        pl.concat_str([&quot;a&quot;, &quot;b&quot;]),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 1)
â”Œâ”€â”€â”€â”€â”€â”
â”‚ a   â”‚
â”‚ --- â”‚
â”‚ str â”‚
â•â•â•â•â•â•â•¡
â”‚ a1  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ b2  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ c3  â”‚
â””â”€â”€â”€â”€â”€â”˜
</code></pre>
<h1 id="window-functions-"><a class="header" href="#window-functions-">Window functions ğŸš€ğŸš€</a></h1>
<p>Window functions are expressions with superpowers. They allow you to do aggregation on groups in the
<strong>select</strong> context. Let's get a feel of what that means. First we create a dataset. The dataset loaded in the
snippet below contains information about pokemon and has the following columns:</p>
<p><code>['#',  'Name',  'Type 1',  'Type 2',  'Total',  'HP',  'Attack',  'Defense',  'Sp. Atk',  'Sp. Def',  'Speed',  'Generation',  'Legendary']</code></p>
<pre><code class="language-python">import polars as pl

# then let's load some csv data with information about pokemon
df = pl.read_csv(
    &quot;https://gist.githubusercontent.com/ritchie46/cac6b337ea52281aa23c049250a4ff03/raw/89a957ff3919d90e6ef2d34235e6bf22304f3366/pokemon.csv&quot;
)
</code></pre>
<pre><code class="language-text">shape: (163, 13)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ #   â”† Name                  â”† Type 1  â”† Type 2 â”† ... â”† Sp. Def â”† Speed â”† Generation â”† Legendary â”‚
â”‚ --- â”† ---                   â”† ---     â”† ---    â”†     â”† ---     â”† ---   â”† ---        â”† ---       â”‚
â”‚ i64 â”† str                   â”† str     â”† str    â”†     â”† i64     â”† i64   â”† i64        â”† bool      â”‚
â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1   â”† Bulbasaur             â”† Grass   â”† Poison â”† ... â”† 65      â”† 45    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2   â”† Ivysaur               â”† Grass   â”† Poison â”† ... â”† 80      â”† 60    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3   â”† Venusaur              â”† Grass   â”† Poison â”† ... â”† 100     â”† 80    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3   â”† VenusaurMega Venusaur â”† Grass   â”† Poison â”† ... â”† 120     â”† 80    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ ... â”† ...                   â”† ...     â”† ...    â”† ... â”† ...     â”† ...   â”† ...        â”† ...       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 147 â”† Dratini               â”† Dragon  â”†        â”† ... â”† 50      â”† 50    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 148 â”† Dragonair             â”† Dragon  â”†        â”† ... â”† 70      â”† 70    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 149 â”† Dragonite             â”† Dragon  â”† Flying â”† ... â”† 100     â”† 80    â”† 1          â”† false     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 150 â”† Mewtwo                â”† Psychic â”†        â”† ... â”† 90      â”† 130   â”† 1          â”† true      â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="groupby-aggregations-in-selection"><a class="header" href="#groupby-aggregations-in-selection">Groupby Aggregations in selection</a></h2>
<p>Below we show how we use window function to group over different columns and do an aggregation on them.
Doing so, allows us to do multiple groupby operations in parallel in a single query. The results of the aggregation
are projected back to the original rows. A window function will therefore always lead to a DataFrame with the same size
as the original.</p>
<pre><code class="language-python">
out = df.select(
    [
        &quot;Type 1&quot;,
        &quot;Type 2&quot;,
        pl.col(&quot;Attack&quot;).mean().over(&quot;Type 1&quot;).alias(&quot;avg_attack_by_type&quot;),
        pl.col(&quot;Defense&quot;).mean().over([&quot;Type 1&quot;, &quot;Type 2&quot;]).alias(&quot;avg_defense_by_type_combination&quot;),
        pl.col(&quot;Attack&quot;).mean().alias(&quot;avg_attack&quot;),
    ]
)
</code></pre>
<pre><code class="language-text">shape: (163, 5)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type 1  â”† Type 2 â”† avg_attack_by_type â”† avg_defense_by_type_combination â”† avg_attack â”‚
â”‚ ---     â”† ---    â”† ---                â”† ---                             â”† ---        â”‚
â”‚ str     â”† str    â”† f64                â”† f64                             â”† f64        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ Grass   â”† Poison â”† 72.923077          â”† 67.8                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Grass   â”† Poison â”† 72.923077          â”† 67.8                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Grass   â”† Poison â”† 72.923077          â”† 67.8                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Grass   â”† Poison â”† 72.923077          â”† 67.8                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ ...     â”† ...    â”† ...                â”† ...                             â”† ...        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Dragon  â”†        â”† 94.0               â”† 55.0                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Dragon  â”†        â”† 94.0               â”† 55.0                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Dragon  â”† Flying â”† 94.0               â”† 95.0                            â”† 75.349693  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Psychic â”†        â”† 53.875             â”† 51.428571                       â”† 75.349693  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="operations-per-group"><a class="header" href="#operations-per-group">Operations per group</a></h2>
<p>In case we want to do something on a group level, we can also use window functions. Below we flex our muscles using them:</p>
<p>We:</p>
<ul>
<li>sort all pokemon by type</li>
<li>select the first 3 pokemon per type as <code>&quot;Type 1&quot;</code></li>
<li>sort the pokemon within a type by speed and select the first 3 as <code>&quot;fastest/group&quot;</code></li>
<li>sort the pokemon within a type by attack and select the first 3 as <code>&quot;strongest/group&quot;</code></li>
<li>sort the pokemon by name within a type and select the first 3 as <code>&quot;sorted_by_alphabet&quot;</code></li>
</ul>
<pre><code class="language-python">
out = df.sort(&quot;Type 1&quot;).select(
    [
        pl.col(&quot;Type 1&quot;).head(3).over(&quot;Type 1&quot;).flatten(),
        pl.col(&quot;Name&quot;).sort_by(pl.col(&quot;Speed&quot;)).head(3).over(&quot;Type 1&quot;).flatten().alias(&quot;fastest/group&quot;),
        pl.col(&quot;Name&quot;).sort_by(pl.col(&quot;Attack&quot;)).head(3).over(&quot;Type 1&quot;).flatten().alias(&quot;strongest/group&quot;),
        pl.col(&quot;Name&quot;).sort().head(3).over(&quot;Type 1&quot;).flatten().alias(&quot;sorted_by_alphabet&quot;),
    ]
)
</code></pre>
<pre><code class="language-text">shape: (43, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type 1 â”† fastest/group       â”† strongest/group â”† sorted_by_alphabet      â”‚
â”‚ ---    â”† ---                 â”† ---             â”† ---                     â”‚
â”‚ str    â”† str                 â”† str             â”† str                     â”‚
â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ Bug    â”† Paras               â”† Metapod         â”† Beedrill                â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Bug    â”† Metapod             â”† Kakuna          â”† BeedrillMega Beedrill   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Bug    â”† Parasect            â”† Caterpie        â”† Butterfree              â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Dragon â”† Dratini             â”† Dratini         â”† Dragonair               â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ ...    â”† ...                 â”† ...             â”† ...                     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Rock   â”† Omanyte             â”† Omastar         â”† Geodude                 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Water  â”† Slowpoke            â”† Magikarp        â”† Blastoise               â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Water  â”† Slowbro             â”† Tentacool       â”† BlastoiseMega Blastoise â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ Water  â”† SlowbroMega Slowbro â”† Horsea          â”† Cloyster                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="flattened-window-function"><a class="header" href="#flattened-window-function">Flattened window function</a></h2>
<p>If we have a window function that aggregates to a <code>list</code> like we did above with the following expression:
<code>pl.col(&quot;Name&quot;).sort_by(pl.col(&quot;Speed&quot;)).head(3).over(&quot;Type 1&quot;)</code> we could just leave it like that, but that
would give us a column type <code>List</code> which is often not what we want (and it increases our memory usage a lot!).</p>
<p>Instead we could <code>flatten</code>. This just turns our 2D list into a 1D array and projects that array/column back to our DataFrame.
This is very fast, because the reshape is often free and adding the column back the the original DataFrame is also a lot cheaper,
because we don't require a join like in a normal window function.</p>
<p>For this operation to make sense however, it is important that the columns used in <code>over([..])</code> are sorted!</p>
<h1 id="numpy-interop"><a class="header" href="#numpy-interop">Numpy interop</a></h1>
<p>Polars expression support numpy <a href="https://numpy.org/doc/stable/reference/ufuncs.html">ufuncs</a>. See <a href="https://numpy.org/doc/stable/reference/ufuncs.html#available-ufuncs">here</a>
for a list on all supported numpy functions.</p>
<p>This means that if a function is not provided by polars, we can use numpy and we still have fast columnar operation through
the numpy API.</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<pre><code class="language-python">import polars as pl
import numpy as np

df = pl.DataFrame({&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [4, 5, 6]})

out = df.select(
    [
        np.log(pl.all()).suffix(&quot;_log&quot;),
    ]
)
print(out)
</code></pre>
<pre><code class="language-text">shape: (3, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ a_log    â”† b_log    â”‚
â”‚ ---      â”† ---      â”‚
â”‚ f64      â”† f64      â”‚
â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 0.0      â”† 1.386294 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 0.693147 â”† 1.609438 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 1.098612 â”† 1.791759 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="gotchas"><a class="header" href="#gotchas">Gotcha's</a></h2>
<p>Read more about the <a href="dsl//howcani/interop/numpy.html">gotcha's here</a></p>
<pre><code class="language-python">import polars as pl

</code></pre>
<h1 id="expressions"><a class="header" href="#expressions">Expressions</a></h1>
<p><code>fn(Series) -&gt; Series</code></p>
<ul>
<li>Lazily evaluated
<ul>
<li>Can be optimized</li>
<li>Gives the library writer context and informed decision can be made</li>
</ul>
</li>
<li>Embarassingly parallel</li>
<li>Context dependent
<ul>
<li>selection / projection -&gt; <code>Series</code> = <strong>COLUMN, LITERAL or VALUE</strong></li>
<li>aggregation -&gt; <code>Series</code> = <strong>GROUPS</strong></li>
</ul>
</li>
</ul>
<pre><code class="language-python">df = pl.DataFrame(
    {
        &quot;A&quot;: [1, 2, 3, 4, 5],
        &quot;fruits&quot;: [&quot;banana&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;apple&quot;, &quot;banana&quot;],
        &quot;B&quot;: [5, 4, 3, 2, 1],
        &quot;cars&quot;: [&quot;beetle&quot;, &quot;audi&quot;, &quot;beetle&quot;, &quot;beetle&quot;, &quot;beetle&quot;],
        &quot;optional&quot;: [28, 300, None, 2, -30],
    }
)
df
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
</tr>
<tr>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
</tr>
<tr>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="selection-context-1"><a class="header" href="#selection-context-1">Selection context</a></h1>
<pre><code class="language-python"># We can select by name
(df.select([
    pl.col(&quot;A&quot;),
    &quot;B&quot;,      # the col part is inferred
    pl.lit(&quot;B&quot;),  # we must tell polars we mean the literal &quot;B&quot;
    pl.col(&quot;fruits&quot;),
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
<th>
literal
</th>
<th>
fruits
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
5
</td>
<td>
"B"
</td>
<td>
"banana"
</td>
</tr>
<tr>
<td>
2
</td>
<td>
4
</td>
<td>
"B"
</td>
<td>
"banana"
</td>
</tr>
<tr>
<td>
3
</td>
<td>
3
</td>
<td>
"B"
</td>
<td>
"apple"
</td>
</tr>
<tr>
<td>
4
</td>
<td>
2
</td>
<td>
"B"
</td>
<td>
"apple"
</td>
</tr>
<tr>
<td>
5
</td>
<td>
1
</td>
<td>
"B"
</td>
<td>
"banana"
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># you can select columns with a regex if it starts with '^' and ends with '$'

(df.select([
    pl.col(&quot;^A|B$&quot;).sum()
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
15
</td>
<td>
15
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># you can select multiple columns by name

(df.select([
    pl.col([&quot;A&quot;, &quot;B&quot;]).sum()
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
15
</td>
<td>
15
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We select everything in normal order
# Then we select everything in reversed order
(df.select([
    pl.all(),
    pl.all().reverse().suffix(&quot;_reverse&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
<th>
A_reverse
</th>
<th>
fruits_reverse
</th>
<th>
B_reverse
</th>
<th>
cars_reverse
</th>
<th>
optional_reverse
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
</tr>
<tr>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
</tr>
<tr>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># all expressions run in parallel
# single valued `Series` are broadcasted to the shape of the `DataFrame`
(df.select([
    pl.all(),
    pl.all().sum().suffix(&quot;_sum&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
<th>
A_sum
</th>
<th>
fruits_sum
</th>
<th>
B_sum
</th>
<th>
cars_sum
</th>
<th>
optional_sum
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
3
</td>
<td>
"apple"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
4
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
<td>
2
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
<td>
15
</td>
<td>
null
</td>
<td>
15
</td>
<td>
null
</td>
<td>
300
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># there are `str` and `dt` namespaces for specialized functions

predicate = pl.col(&quot;fruits&quot;).str.contains(&quot;^b.*&quot;)

(df.select([
    predicate
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
</tr>
<tr>
<td>
bool
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
true
</td>
</tr>
<tr>
<td>
true
</td>
</tr>
<tr>
<td>
false
</td>
</tr>
<tr>
<td>
false
</td>
</tr>
<tr>
<td>
true
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># use the predicate to filter

df.filter(predicate)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
fruits
</th>
<th>
B
</th>
<th>
cars
</th>
<th>
optional
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
"banana"
</td>
<td>
5
</td>
<td>
"beetle"
</td>
<td>
28
</td>
</tr>
<tr>
<td>
2
</td>
<td>
"banana"
</td>
<td>
4
</td>
<td>
"audi"
</td>
<td>
300
</td>
</tr>
<tr>
<td>
5
</td>
<td>
"banana"
</td>
<td>
1
</td>
<td>
"beetle"
</td>
<td>
-30
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># predicate expressions can be used to filter

(df.select([
    pl.col(&quot;A&quot;).filter(pl.col(&quot;fruits&quot;).str.contains(&quot;^b.*&quot;)).sum(),
    (pl.col(&quot;B&quot;).filter(pl.col(&quot;cars&quot;).str.contains(&quot;^b.*&quot;)).sum() * pl.col(&quot;B&quot;).sum()).alias(&quot;some_compute()&quot;),
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
some_compute()
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
8
</td>
<td>
165
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can do arithmetic on columns and (literal) values

# can be evaluated to 1 without programmer knowing
some_var = 1

(df.select([
    ((pl.col(&quot;A&quot;) / 124.0 * pl.col(&quot;B&quot;)) / pl.sum(&quot;B&quot;) * some_var).alias(&quot;computed&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
computed
</th>
</tr>
<tr>
<td>
f64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
<tr>
<td>
0.0
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can combine columns by a predicate

(df.select([
    &quot;fruits&quot;,
    &quot;B&quot;,
    pl.when(pl.col(&quot;fruits&quot;) == &quot;banana&quot;).then(pl.col(&quot;B&quot;)).otherwise(-1).alias(&quot;b&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
<th>
b
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
5
</td>
<td>
5
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
4
</td>
<td>
4
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
3
</td>
<td>
-1
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2
</td>
<td>
-1
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
1
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can combine columns by a fold operation on column level

(df.select([
    &quot;A&quot;,
    &quot;B&quot;,
    pl.fold(0, lambda a, b: a + b, [pl.col(&quot;A&quot;), &quot;B&quot;, pl.col(&quot;B&quot;)**2, pl.col(&quot;A&quot;) / 2.0]).alias(&quot;fold&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
A
</th>
<th>
B
</th>
<th>
fold
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
<td>
f64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
5
</td>
<td>
31
</td>
</tr>
<tr>
<td>
2
</td>
<td>
4
</td>
<td>
23
</td>
</tr>
<tr>
<td>
3
</td>
<td>
3
</td>
<td>
16
</td>
</tr>
<tr>
<td>
4
</td>
<td>
2
</td>
<td>
12
</td>
</tr>
<tr>
<td>
5
</td>
<td>
1
</td>
<td>
9
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># even combine all

(df.select([
    pl.arange(0, df.height).alias(&quot;idx&quot;),
    &quot;A&quot;,
    pl.col(&quot;A&quot;).shift().alias(&quot;A_shifted&quot;),
    pl.concat_str(pl.all(), &quot;-&quot;).alias(&quot;str_concat_1&quot;),  # prefer this
    pl.fold(pl.col(&quot;A&quot;), lambda a, b: a + &quot;-&quot; + b, pl.all().exclude(&quot;A&quot;)).alias(&quot;str_concat_2&quot;),  # over this (accidentally O(n^2))
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
idx
</th>
<th>
A
</th>
<th>
A_shifted
</th>
<th>
str_concat_1
</th>
<th>
str_concat_2
</th>
</tr>
<tr>
<td>
i64
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
0
</td>
<td>
1
</td>
<td>
null
</td>
<td>
"1-banana-5-beetle-28"
</td>
<td>
"1-banana-5-beetle-28"
</td>
</tr>
<tr>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
"2-banana-4-audi-300"
</td>
<td>
"2-banana-4-audi-300"
</td>
</tr>
<tr>
<td>
2
</td>
<td>
3
</td>
<td>
2
</td>
<td>
null
</td>
<td>
null
</td>
</tr>
<tr>
<td>
3
</td>
<td>
4
</td>
<td>
3
</td>
<td>
"4-apple-2-beetle-2"
</td>
<td>
"4-apple-2-beetle-2"
</td>
</tr>
<tr>
<td>
4
</td>
<td>
5
</td>
<td>
4
</td>
<td>
"5-banana-1-beetle--30"
</td>
<td>
"5-banana-1-beetle--30"
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="aggregation-context"><a class="header" href="#aggregation-context">Aggregation context</a></h1>
<ul>
<li>expression are applied over groups instead of columns</li>
</ul>
<pre><code class="language-python"># we can still combine many expressions

(df.sort(&quot;cars&quot;).groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum(),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;),
        pl.count(&quot;A&quot;).alias(&quot;count&quot;),
        pl.col(&quot;cars&quot;).reverse()
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
list
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
[beetle, beetle, audi]
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
[beetle, beetle]
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># We can explode the list column &quot;cars&quot;

(df.sort(&quot;cars&quot;).groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum(),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;),
        pl.count(&quot;A&quot;).alias(&quot;count&quot;),
        pl.col(&quot;cars&quot;).reverse()
    ])).explode(&quot;cars&quot;)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
str
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"beetle"
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
"audi"
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python">(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).sum(),
        pl.sum(&quot;B&quot;).alias(&quot;B_sum2&quot;),  # syntactic sugar for the first
        pl.first(&quot;fruits&quot;),
        pl.count(&quot;A&quot;).alias(&quot;count&quot;),
        pl.col(&quot;B&quot;).shift().alias(&quot;B_shifted&quot;)
    ])
 .explode(&quot;B_shifted&quot;)
)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_sum
</th>
<th>
B_sum2
</th>
<th>
fruits_first
</th>
<th>
count
</th>
<th>
B_shifted
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
str
</td>
<td>
u32
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
5
</td>
<td>
5
</td>
<td>
"apple"
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
5
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
10
</td>
<td>
10
</td>
<td>
"banana"
</td>
<td>
3
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># we can also get the list of the groups
(df.groupby(&quot;fruits&quot;)
    .agg([
         pl.col(&quot;B&quot;).shift().alias(&quot;shift_B&quot;),
         pl.col(&quot;B&quot;).reverse().alias(&quot;rev_B&quot;),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
shift_B
</th>
<th>
rev_B
</th>
</tr>
<tr>
<td>
str
</td>
<td>
list
</td>
<td>
list
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
[null, 3]
</td>
<td>
[2, 3]
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
[null, 5, 4]
</td>
<td>
[1, 4, 5]
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># we can do predicates in the groupby as well

(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).filter(pl.col(&quot;B&quot;) &gt; 1).list().keep_name(),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
</tr>
<tr>
<td>
str
</td>
<td>
list
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
[5, 4]
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
[3, 2]
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># and sum only by the values where the predicates are true

(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).filter(pl.col(&quot;B&quot;) &gt; 1).mean(),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B_mean
</th>
</tr>
<tr>
<td>
str
</td>
<td>
f64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"banana"
</td>
<td>
4.5
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2.5
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># Another example
(df.groupby(&quot;fruits&quot;)
    .agg([
        pl.col(&quot;B&quot;).shift_and_fill(1, fill_value=0).alias(&quot;shifted&quot;),
        pl.col(&quot;B&quot;).shift_and_fill(1, fill_value=0).sum().alias(&quot;shifted_sum&quot;),
    ]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
shifted
</th>
<th>
shifted_sum
</th>
</tr>
<tr>
<td>
str
</td>
<td>
list
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
[0, 3]
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
[0, 5, 4]
</td>
<td>
9
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="window-functions"><a class="header" href="#window-functions">Window functions!</a></h1>
<ul>
<li>Expression with superpowers.</li>
<li>Aggregation in selection context</li>
</ul>
<pre><code class="language-python">pl.col(&quot;foo&quot;).aggregation_expression(..).over(&quot;column_used_to_group&quot;)
</code></pre>
<pre><code class="language-python"># groupby 2 different columns

(df.sort(&quot;fruits&quot;)
.select([
    &quot;fruits&quot;,
    &quot;cars&quot;,
    &quot;B&quot;,
    pl.col(&quot;B&quot;).sum().over(&quot;fruits&quot;).alias(&quot;B_sum_by_fruits&quot;),
    pl.col(&quot;B&quot;).sum().over(&quot;cars&quot;).alias(&quot;B_sum_by_cars&quot;),
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
cars
</th>
<th>
B
</th>
<th>
B_sum_by_fruits
</th>
<th>
B_sum_by_cars
</th>
</tr>
<tr>
<td>
str
</td>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
"beetle"
</td>
<td>
3
</td>
<td>
5
</td>
<td>
11
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
"beetle"
</td>
<td>
2
</td>
<td>
5
</td>
<td>
11
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
"beetle"
</td>
<td>
5
</td>
<td>
10
</td>
<td>
11
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
"audi"
</td>
<td>
4
</td>
<td>
10
</td>
<td>
4
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
"beetle"
</td>
<td>
1
</td>
<td>
10
</td>
<td>
11
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># reverse B by groups and show the results in original DF

(df.sort(&quot;fruits&quot;)
.select([
    &quot;fruits&quot;,
    &quot;B&quot;,
    pl.col(&quot;B&quot;).reverse().over(&quot;fruits&quot;).flatten().alias(&quot;B_reversed_by_fruits&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
<th>
B_reversed_by_fruits
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
3
</td>
<td>
2
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
5
</td>
<td>
1
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
4
</td>
<td>
4
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
1
</td>
<td>
5
</td>
</tr>
</tbody>
</table>
</div>
<pre><code class="language-python"># Lag a column within &quot;fruits&quot;
(df
.sort(&quot;fruits&quot;)
.select([
    &quot;fruits&quot;,
    &quot;B&quot;,
    pl.col(&quot;B&quot;).shift().over(&quot;fruits&quot;).flatten().alias(&quot;lag_B_by_fruits&quot;)
]))
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1 "class="dataframe ">
<thead>
<tr>
<th>
fruits
</th>
<th>
B
</th>
<th>
lag_B_by_fruits
</th>
</tr>
<tr>
<td>
str
</td>
<td>
i64
</td>
<td>
i64
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
"apple"
</td>
<td>
3
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"apple"
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
5
</td>
<td>
null
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
4
</td>
<td>
5
</td>
</tr>
<tr>
<td>
"banana"
</td>
<td>
1
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
</div>
<h1 id="expression-api"><a class="header" href="#expression-api">Expression API</a></h1>
<p>The full list of possible expressions is available on the <a href="https://pola-rs.github.io/polars/py-polars/html/reference/expression.html"><code>Expr</code></a>
class definition in the reference guide.</p>
<h1 id="indexing"><a class="header" href="#indexing">Indexing</a></h1>
<p>Polars DataFrames don't have an index and therefore indexing behavior can be consistent without the need of a <code>df.loc</code>,
<code>df.iloc</code>, or a <code>df.at</code> operation.</p>
<p>The rules are as follows, depending on the datatypes of the index values:</p>
<ul>
<li>
<p><strong>numeric</strong></p>
<ul>
<li>axis 0: row</li>
<li>axis 1: column</li>
</ul>
</li>
<li>
<p><strong>numeric + strings</strong></p>
<ul>
<li>axis 0: row (only accept numbers here)</li>
<li>axis 1: column (accept numeric + string values)</li>
</ul>
</li>
<li>
<p><strong>only strings</strong></p>
<ul>
<li>axis 0: column</li>
<li>axis 1: error</li>
</ul>
</li>
<li>
<p><strong>expressions</strong></p>
<p><em>All expression evaluations are executed in parallel</em></p>
<ul>
<li>axis 0: column</li>
<li>axis 1: column</li>
<li>..</li>
<li>axis n: column</li>
</ul>
</li>
</ul>
<h2 id="comparison-with-pandas"><a class="header" href="#comparison-with-pandas">Comparison with pandas</a></h2>
<table><thead><tr><th>pandas</th><th>polars</th></tr></thead><tbody>
<tr><td>select row<br> <code>df.iloc[2]</code></td><td><code>df[2, :]</code></td></tr>
<tr><td>select several rows by their indices<br> <code>df.iloc[[2, 5, 6]]</code></td><td><code>df[[2, 5, 6], :]</code></td></tr>
<tr><td>select slice of rows<br> <code>df.iloc[2:6]</code></td><td><code>df[2:6, :]</code></td></tr>
<tr><td>select rows using a boolean mask<br> <code>df.iloc[True, True, False]</code></td><td><code>df[[True, True, False]]</code></td></tr>
<tr><td>select slice of rows<br> <code>df.iloc[2:6]</code></td><td><code>df[2:6, :]</code></td></tr>
<tr><td>select rows by a predicate condition<br> <code>df.loc[df[&quot;A&quot;] &gt; 3]</code></td><td><code>df[df[&quot;A&quot;] &gt; 3]</code></td></tr>
<tr><td>select slice of columns<br> <code>df.iloc[:, 1:3]</code></td><td><code>df[:, 1:3]</code></td></tr>
<tr><td>select slice of columns by string order<br> <code>df.loc[:, &quot;A&quot;:&quot;Z&quot;]</code></td><td><code>df[:, &quot;A&quot;:&quot;Z&quot;]</code></td></tr>
<tr><td>select a single value (scalar)<br> <code>df.loc[2, &quot;A&quot;]</code></td><td><code>df[2, &quot;A&quot;]</code></td></tr>
<tr><td>select a single value (scalar)<br> <code>df.iloc[2, 1]</code></td><td><code>df[2, 1]</code></td></tr>
<tr><td>select a single value (Series/DataFrame)<br> <code>df.loc[2, [&quot;A&quot;]]</code></td><td><code>df[2, [&quot;A&quot;]]</code></td></tr>
<tr><td>select a single value (Series/DataFrame)<br> <code>df.iloc[2, [1]]</code></td><td><code>df[2, [1]]</code></td></tr>
</tbody></table>
<h2 id="expressions-1"><a class="header" href="#expressions-1">Expressions</a></h2>
<p>Expressions can also be used in indexing (it is syntactic sugar for <code>df.select</code>).</p>
<p>This can be used to do some pretty exotic selections.</p>
<pre><code class="language-python">df[[
    pl.col(&quot;A&quot;).head(5),  # get first of &quot;A&quot;
    pl.col(&quot;B&quot;).tail(5).reverse(), # get last of &quot;B&quot; in reversed order
    pl.col(&quot;B&quot;).filter(pl.col(&quot;B&quot;) &gt; 5).head(5), # get first of &quot;B&quot; that fulfils predicate
    pl.sum(&quot;A&quot;).over(&quot;B&quot;).head(5) # get the sum aggregation of &quot;A&quot; over the groups of &quot;B&quot; and return the first 5
]]
</code></pre>
<h1 id="data-types"><a class="header" href="#data-types">Data types</a></h1>
<p>Polars is entirely based on Arrow data types and backed by Arrow memory arrays. This makes data processing
cache-efficient and well-supported for Inter Process Communication. Most data types follow the exact implementation
from Arrow, with exception of <code>Utf8</code> (this is actually <code>LargeUtf8</code>), <code>Categorical</code>, and <code>Object</code> (support is limited).</p>
<p>The data types are:</p>
<ul>
<li><code>Int8</code>: 8-bit signed integer.</li>
<li><code>Int16</code>: 16-bit signed integer.</li>
<li><code>Int32</code>: 32-bit signed integer.</li>
<li><code>Int64</code>: 64-bit signed integer.</li>
<li><code>UInt8</code>: 8-bit unsigned integer.</li>
<li><code>UInt16</code>: 16-bit unsigned integer.</li>
<li><code>UInt32</code>: 32-bit unsigned integer.</li>
<li><code>UInt64</code>: 64-bit unsigned integer.</li>
<li><code>Float32</code>: 32-bit floating point.</li>
<li><code>Float64</code>: 64-bit floating point.</li>
<li><code>Boolean</code>: Boolean type effectively bit packed.</li>
<li><code>Utf8</code>: String data (this is actually Arrow <code>LargeUtf8</code> internally).</li>
<li><code>List</code>: A list array contains a child array containing the list values and an offset array. (this is actually Arrow <code>LargeList</code> internally).</li>
<li><code>Date</code>: Date representation, internally represented as days since UNIX epoch encoded by a 32-bit signed integer.</li>
<li><code>Datetime</code>: Datetime representation, internally represented as nanoseconds since UNIX epoch encoded by a 64-bit signed integer.</li>
<li><code>Time</code>: Time representation, internally represented as nanoseconds since midnight.</li>
<li><code>Object</code>: A limited supported data type that can be any value.</li>
</ul>
<p>To learn more about the internal representation of these data types, check the <a href="https://arrow.apache.org/docs/format/Columnar.html">Arrow columnar format</a>.</p>
<h1 id="coming-from-pandas"><a class="header" href="#coming-from-pandas">Coming from pandas</a></h1>
<p>Users coming from <code>pandas</code> generally need to know one thing...</p>
<pre><code>polars != pandas
</code></pre>
<p>If your polars code looks like it could be pandas code, it might run, but it likely runs slower than it has to be.</p>
<p>Let's go through some typical pandas code and see how we might write that in polars</p>
<h2 id="column-assignment"><a class="header" href="#column-assignment">Column assignment</a></h2>
<p><strong>pandas</strong></p>
<pre><code class="language-python"># executes sequential
df[&quot;a&quot;] = df[&quot;b&quot;] * 10
df[&quot;c&quot;] = df[&quot;b&quot;] * 100
</code></pre>
<p><strong>polars</strong></p>
<pre><code class="language-python"># executes in parallel
df.with_columns([
    (pl.col(&quot;b&quot;) * 10).alias(&quot;a&quot;),
    (pl.col(&quot;b&quot;) * 100).alias(&quot;c&quot;),
])
</code></pre>
<h2 id="column-asignment-based-on-predicate"><a class="header" href="#column-asignment-based-on-predicate">Column asignment based on predicate</a></h2>
<p><strong>pandas</strong></p>
<pre><code class="language-python">df[df[&quot;c&quot;] == 2, &quot;a&quot;] = df[df[&quot;c&quot;] == 2, &quot;b&quot;]
</code></pre>
<p><strong>polars</strong></p>
<pre><code class="language-python">df.with_column(
    pl.when(pl.col(&quot;c&quot;) == 2)
    .then(pl.col(&quot;c&quot;))
    .otherwise(pl.col(&quot;a&quot;)).alias(&quot;a&quot;)
)
</code></pre>
<p>Not that polars way is pure (the original DataFrame) is not modified. The <code>mask</code> is also not computed twice as in <code>pandas</code>.
You could prevent this in <code>pandas</code>, but that would require setting a temporary variable.
Additionally polars can compute every branch of an <code>if -&gt; then -&gt; otherwise</code> in parallel. This is valuable, when the branches
get more expensive to compute.</p>
<h2 id="filtering-1"><a class="header" href="#filtering-1">Filtering</a></h2>
<p><strong>pandas</strong></p>
<pre><code class="language-python">df.loc[(df['sqft_living'] &gt; 2500) &amp; (df['price'] &lt; 300000)]
</code></pre>
<p><strong>polars</strong></p>
<pre><code class="language-python">df.filter(
    (pl.col(&quot;m2_living&quot;) &gt; 2500) &amp; (pl.col(&quot;price&quot;) &lt; 300000)
)
</code></pre>
<blockquote>
<p>More in redaction. Miss something? make a PR :).</p>
</blockquote>
<h2 id="no-index"><a class="header" href="#no-index">No index</a></h2>
<p>They are not needed. Not having them makes things easier. Convince me otherwise</p>
<h1 id="time-series"><a class="header" href="#time-series">Time-series</a></h1>
<blockquote>
<p>In Redaction</p>
</blockquote>
<p>We are still working on this page. But here is already some example to show how we can use <code>groupby_dynamic</code> to group by
a time window.</p>
<pre><code class="language-python">import polars as pl
from datetime import datetime
# create an example dataframe
df = pl.DataFrame(
    {
        &quot;time&quot;: pl.date_range(
            low=datetime(2021, 12, 16),
            high=datetime(2021, 12, 16, 3),
            interval=&quot;30m&quot;,
        ),
        &quot;n&quot;: range(7),
    }
)
df
</code></pre>
<pre><code>shape: (7, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ time                â”† n   â”‚
â”‚ ---                 â”† --- â”‚
â”‚ datetime            â”† i64 â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡
â”‚ 2021-12-16 00:00:00 â”† 0   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 00:30:00 â”† 1   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:00:00 â”† 2   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:30:00 â”† 3   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:00:00 â”† 4   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:30:00 â”† 5   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 03:00:00 â”† 6   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Group by windows of 1 hour starting at 2021-12-16 00:00:00.</p>
<pre><code class="language-python">(
    df.groupby_dynamic(&quot;time&quot;, every=&quot;1h&quot;).agg(
        [pl.col(&quot;time&quot;).min(), pl.col(&quot;time&quot;).max()]
    )
)
</code></pre>
<pre><code>shape: (3, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ time                â”† time_min            â”† time_max            â”‚
â”‚ ---                 â”† ---                 â”† ---                 â”‚
â”‚ datetime            â”† datetime            â”† datetime            â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 2021-12-16 00:00:00 â”† 2021-12-16 00:30:00 â”† 2021-12-16 01:00:00 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:00:00 â”† 2021-12-16 01:30:00 â”† 2021-12-16 02:00:00 â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:00:00 â”† 2021-12-16 02:30:00 â”† 2021-12-16 03:00:00 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>The window boundaries can also be added to the aggregation result</p>
<pre><code class="language-python">(
    df.groupby_dynamic(&quot;time&quot;, every=&quot;1h&quot;, include_boundaries=True).agg(
        [pl.col(&quot;time&quot;).count()]
    )
)
</code></pre>
<pre><code>shape: (3, 4)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _lower_boundary     â”† _upper_boundary     â”† time                â”† time_count â”‚
â”‚ ---                 â”† ---                 â”† ---                 â”† ---        â”‚
â”‚ datetime            â”† datetime            â”† datetime            â”† u32        â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 2021-12-16 00:00:00 â”† 2021-12-16 01:00:00 â”† 2021-12-16 00:00:00 â”† 2          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:00:00 â”† 2021-12-16 02:00:00 â”† 2021-12-16 01:00:00 â”† 2          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:00:00 â”† 2021-12-16 03:00:00 â”† 2021-12-16 02:00:00 â”† 2          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>When closed=&quot;left&quot;, should not include right end of interval [lower_bound, upper_bound)</p>
<pre><code class="language-python">(
    df.groupby_dynamic(&quot;time&quot;, every=&quot;1h&quot;, closed=&quot;left&quot;).agg(
        [pl.col(&quot;time&quot;).count(), pl.col(&quot;time&quot;).list()]
    )
)
</code></pre>
<pre><code>shape: (3, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ time                â”† time_count â”† time_agg_list                       â”‚
â”‚ ---                 â”† ---        â”† ---                                 â”‚
â”‚ datetime            â”† u32        â”† list [datetime]                     â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 2021-12-16 00:00:00 â”† 2          â”† [2021-12-16 00:00:00, 2021-12-16... â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:00:00 â”† 2          â”† [2021-12-16 01:00:00, 2021-12-16... â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:00:00 â”† 2          â”† [2021-12-16 02:00:00, 2021-12-16... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>When closed=&quot;both&quot; the time values at the window boundaries belong to 2 groups.</p>
<pre><code class="language-python">(
    df.groupby_dynamic(&quot;time&quot;, every=&quot;1h&quot;, closed=&quot;both&quot;).agg(
        [pl.col(&quot;time&quot;).count()]
    )
)
</code></pre>
<pre><code>shape: (3, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ time                â”† time_count â”‚
â”‚ ---                 â”† ---        â”‚
â”‚ datetime            â”† u32        â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 2021-12-16 00:00:00 â”† 3          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:00:00 â”† 3          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:00:00 â”† 3          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Dynamic groupbys can also be combined with grouping on normal keys</p>
<pre><code class="language-python">pl.DataFrame(
    {
        &quot;time&quot;: pl.date_range(
            low=datetime(2021, 12, 16),
            high=datetime(2021, 12, 16, 3),
            interval=&quot;30m&quot;,
        ),
        &quot;groups&quot;: [&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;],
    }
)
</code></pre>
<pre><code>shape: (7, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ time                â”† groups â”‚
â”‚ ---                 â”† ---    â”‚
â”‚ datetime            â”† str    â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚ 2021-12-16 00:00:00 â”† a      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 00:30:00 â”† a      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:00:00 â”† a      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 01:30:00 â”† b      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:00:00 â”† b      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 02:30:00 â”† a      â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2021-12-16 03:00:00 â”† a      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<pre><code class="language-python">(
    df.groupby_dynamic(
        &quot;time&quot;,
        every=&quot;1h&quot;,
        closed=&quot;both&quot;,
        by=&quot;groups&quot;,
        include_boundaries=True,
    ).agg([pl.col(&quot;time&quot;).count()])
)
</code></pre>
<pre><code>shape: (4, 5)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ groups â”† _lower_boundary     â”† _upper_boundary     â”† time                â”† time_count â”‚
â”‚ ---    â”† ---                 â”† ---                 â”† ---                 â”† ---        â”‚
â”‚ str    â”† datetime            â”† datetime            â”† datetime            â”† u32        â”‚
â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ a      â”† 2021-12-16 00:00:00 â”† 2021-12-16 01:00:00 â”† 2021-12-16 00:00:00 â”† 3          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ a      â”† 2021-12-16 01:00:00 â”† 2021-12-16 02:00:00 â”† 2021-12-16 01:00:00 â”† 1          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ a      â”† 2021-12-16 02:00:00 â”† 2021-12-16 03:00:00 â”† 2021-12-16 02:00:00 â”† 2          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ b      â”† 2021-12-16 01:00:00 â”† 2021-12-16 02:00:00 â”† 2021-12-16 01:00:00 â”† 2          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h1 id="how-can-i"><a class="header" href="#how-can-i">How can I?</a></h1>
<p>This chapter contains some snippets that will get you up to speed with the most
idiomatic way to get things done in <code>Polars</code>.</p>
<h1 id="io"><a class="header" href="#io">IO</a></h1>
<p>Polars support different file types and its respective parsers are amongst the fastest
out there.</p>
<p>For instance, it is faster to load a CSV file <em>via</em> <code>Polars</code> before handing it <code>Pandas</code>,
than directly using <code>Pandas</code>. (Just run a
<code>pl.read_csv(&quot;&lt;FILE&gt;&quot;, rechunk=False).to_pandas()</code> to convince yourself.)</p>
<h1 id="character-separated-values"><a class="header" href="#character-separated-values">Character-Separated Values</a></h1>
<h2 id="read--write"><a class="header" href="#read--write">Read &amp; Write</a></h2>
<p>Reading a CSV file should look familiar:</p>
<pre><code class="language-python">df = pl.read_csv(&quot;path.csv&quot;)
</code></pre>
<p>CSV files come in many different flavors, so make sure to check the
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.read_csv.html"><code>read_csv()</code></a> API.</p>
<p>Writing to a CSV file can be done with the
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.to_csv.html"><code>to_csv()</code></a> method.</p>
<pre><code class="language-python">df = pl.DataFrame({&quot;foo&quot;: [1, 2, 3], &quot;bar&quot;: [None, &quot;bak&quot;, &quot;baz&quot;]})
df.to_csv(&quot;path.csv&quot;)
</code></pre>
<h2 id="scan"><a class="header" href="#scan">Scan</a></h2>
<p><code>Polars</code> allows to <em>scan</em> a CSV input. Scanning delays the actual parsing of the file,
and returns instead a lazy computation holder called a <code>LazyFrame</code>.</p>
<pre><code class="language-python">df = pl.scan_csv(&quot;path.csv&quot;)
</code></pre>
<p>If you want to know why you would want this (and you do!)
<a href="howcani/io/../../optimizations/intro.html">read about the optimizations</a> run under the hood of
<code>Polars</code>.</p>
<h1 id="parquet"><a class="header" href="#parquet">Parquet</a></h1>
<p>Loading or writing <a href="https://parquet.apache.org/"><code>Parquet</code> files</a> is as fast as can be.
<code>Pandas</code> uses <a href="https://arrow.apache.org/docs/python/"><code>PyArrow</code></a> -<code>Python</code> bindings
exposed by <code>Arrow</code>- to load <code>Parquet</code> files into memory but has to copy that data into
<code>Pandas</code> own memory. With <code>Polars</code> one does not have to pay the extra price due to
copying as we read <code>Parquet</code> directly into <code>Arrow memory</code> and <em>keep it there</em>.</p>
<h2 id="read--write-1"><a class="header" href="#read--write-1">Read &amp; write</a></h2>
<pre><code class="language-python">df = pl.read_parquet(&quot;path.parquet&quot;)
</code></pre>
<pre><code class="language-python">df = pl.DataFrame({&quot;foo&quot;: [1, 2, 3], &quot;bar&quot;: [None, &quot;bak&quot;, &quot;baz&quot;]})
df.to_parquet(&quot;path.parquet&quot;)
</code></pre>
<h2 id="scan-1"><a class="header" href="#scan-1">Scan</a></h2>
<p><code>Polars</code> allows to <em>scan</em> a <code>Parquet</code> input. Scanning delays the actual parsing of the
file, and returns instead a lazy computation holder called a <code>LazyFrame</code>.</p>
<pre><code class="language-python">df = pl.scan_parquet(&quot;path.parquet&quot;)
</code></pre>
<p>If you want to know why you would want this (and you do!)
<a href="howcani/io/../../optimizations/intro.html">read about the optimizations</a> run under the hood of
<code>Polars</code>.</p>
<h1 id="read-from-mysql-postgres-sqlite-redshift-clickhouse"><a class="header" href="#read-from-mysql-postgres-sqlite-redshift-clickhouse">Read from MySQL, Postgres, Sqlite, Redshift, Clickhouse</a></h1>
<p>To read from one of the supported databases <code>connector-x</code> needs to be installed.</p>
<pre><code class="language-shell">$  pip install connectorx&gt;=0.2.0a3
</code></pre>
<pre><code class="language-python">import polars as pl

conn = &quot;postgres://username:password@server:port/database&quot;
query = &quot;SELECT * FROM foo&quot;

pl.read_sql(query, conn)
</code></pre>
<h1 id="interact-with-aws"><a class="header" href="#interact-with-aws">Interact with AWS</a></h1>
<blockquote>
<p>In redaction</p>
</blockquote>
<p>To read from or write to an AWS bucket, additional dependencies are needed:</p>
<pre><code class="language-shell">$ pip install s3fs
</code></pre>
<p>In the next few snippets, we take the example of interacting with a <code>Parquet</code> file
located on an AWS bucket.</p>
<h2 id="read"><a class="header" href="#read">Read</a></h2>
<p>One can load a <code>.parquet</code> file using:</p>
<pre><code class="language-python">import polars as pl
import pyarrow.parquet as pq
import s3fs

fs = s3fs.S3FileSystem()
bucket = &quot;&lt;YOUR_BUCKET&gt;&quot;
path = &quot;&lt;YOUR_PATH&gt;&quot;

dataset = pq.ParquetDataset(f&quot;s3://{bucket}/{path}&quot;, filesystem=fs)
df = pl.from_arrow(dataset.read())
</code></pre>
<h2 id="write"><a class="header" href="#write">Write</a></h2>
<h1 id="interact-with-google-bigquery"><a class="header" href="#interact-with-google-bigquery">Interact with Google BigQuery</a></h1>
<p>To read/write form GBQ, additional dependencies are needed:</p>
<pre><code class="language-shell">$ pip install google-cloud-bigquery
</code></pre>
<h2 id="read-1"><a class="header" href="#read-1">Read</a></h2>
<p>We can load a query into a DataFrame like this:</p>
<pre><code class="language-python">import polars as pl
from google.cloud import bigquery

client = bigquery.Client()

# Perform a query.
QUERY = (
    'SELECT name FROM `bigquery-public-data.usa_names.usa_1910_2013` '
    'WHERE state = &quot;TX&quot; '
    'LIMIT 100')
query_job = client.query(QUERY)  # API request
rows = query_job.result()  # Waits for query to finish

df = pl.from_arrow(rows.to_arrow())
</code></pre>
<h2 id="write-1"><a class="header" href="#write-1">Write</a></h2>
<blockquote>
<p>In redaction</p>
</blockquote>
<h1 id="interact-with-postgres"><a class="header" href="#interact-with-postgres">Interact with Postgres</a></h1>
<h2 id="read-2"><a class="header" href="#read-2">Read</a></h2>
<p>To read from postgres, additional dependencies are needed:</p>
<pre><code class="language-shell">$  pip install connectorx&gt;=0.2.0a3
</code></pre>
<pre><code class="language-python">import polars as pl

conn = &quot;postgresql://username:password@server:port/database&quot;
query = &quot;SELECT * FROM foo&quot;

pl.read_sql(query, conn)
</code></pre>
<h2 id="write-2"><a class="header" href="#write-2">Write</a></h2>
<p>To write to postgres, additional dependencies are needed:</p>
<pre><code class="language-shell">$ pip install psycopg2-binary
</code></pre>
<p>For writing to a postgres database with <code>psycopg2</code>, we utilize <code>execute_batch</code>. This will limit the needed round trips
to the server.</p>
<p>We first make sure that all our dtypes are in a format that <code>psycopg2</code> recognizes, and then we use <code>DataFrame.rows</code> to
easily transform the columnar data to rows that the database driver can work with.</p>
<pre><code class="language-python">from psycopg2 import sql
import psycopg2.extras
import polars as pl

# let's assume we have a DataFrame with some floats, integers, strings, and date64 columns.
df = pl.read_parquet(&quot;somefile.parquet&quot;)

# first me convert polars date64 representation to python datetime objects 
for col in df:
    # only for date64
    if col.dtype == pl.Date64:
        df = df.with_column(col.dt.to_python_datetime())

# create sql identifiers for the column names
# we do this to safely insert this into a sql query
columns = sql.SQL(&quot;,&quot;).join(sql.Identifier(name) for name in df.columns)

# create placeholders for the values. These will be filled later
values = sql.SQL(&quot;,&quot;).join([sql.Placeholder() for _ in df.columns])

table_id = &quot;mytable&quot;

# prepare the insert query
insert_stmt = sql.SQL(&quot;INSERT INTO ({}) VALUES({});&quot;).format(
    sql.Identifier(table_id), columns, values
)

# make a connection
conn = psycopg2.connect()
cur = conn.cursort()

# do the insert
psycopg2.extras.execute_batch(cur, insert_stmt, df.rows())
conn.commit()
</code></pre>
<h1 id="interoperability"><a class="header" href="#interoperability">Interoperability</a></h1>
<h1 id="arrow"><a class="header" href="#arrow">Arrow</a></h1>
<p><code>Arrow</code> is rapidly becoming the <em>de facto</em> standard for columnar data. This means that
support for <code>Arrow</code> is growing rapidly, in languages and in tools. Due to the great
effort that is being put in the format, using <code>Arrow</code> is now likely the fastest way to:</p>
<ul>
<li>Read and write <code>Parquet</code> formatted files.</li>
<li>Read CSV into columnar data.</li>
<li>Exchanging columnar data.</li>
</ul>
<p><code>Polars</code> uses <code>Arrow</code> memory buffer as the most basic building block for <code>Polars</code>
<code>Series</code>. This means that we exchange data between <code>Polars</code> and <code>Arrow</code> <strong>without
copying</strong> it. It also means that where <code>Arrow</code> performs well, <code>Polars</code> does.</p>
<p>One can convert a <code>Polars</code> <code>DataFrame</code> or <code>Series</code> to <code>Arrow</code> using the <code>.to_arrow()</code>
method. Similarly, importing from <code>Arrow</code> data structure can be performed with the
<code>.from_arrow()</code> functions.</p>
<h1 id="numpy"><a class="header" href="#numpy">NumPy</a></h1>
<p><code>Polars</code> <code>Series</code> have support for <code>NumPy</code>
<a href="https://numpy.org/doc/stable/reference/ufuncs.html">universal functions (ufuncs)</a>.
Element-wise function such as <code>np.exp()</code>, <code>np.cos()</code>, <code>np.div()</code>, <em>etc.</em> all work with
almost zero overhead.</p>
<p>A <code>Polars</code>-specific remark however: missing values are a separate bitmask and are not
visible by <code>NumPy</code>. It can yield to a window function or a <code>np.convolve()</code> giving
flawed/incomplete results.</p>
<p>One can convert a <code>Polars</code> <code>Series</code> to a <code>NumPy</code> array with the <code>.to_numpy()</code> method.
Missing values will be replaced by <code>np.nan</code> during the conversion. If the <code>Series</code> does
not include missing values, or those values are not desired anymore, the <code>.view()</code>
method can be used instead, providing a zero-copy <code>NumPy</code> array of the data.</p>
<h1 id="data-handling"><a class="header" href="#data-handling">Data handling</a></h1>
<h1 id="process-strings"><a class="header" href="#process-strings">Process strings</a></h1>
<p>Thanks to its <code>Arrow</code> backend <code>Polars</code> string operations are much faster compared to the
same operations performed with <code>NumPy</code> or <code>Pandas</code>. In the latter, strings are stored as
<code>Python</code> objects and while traversing the <code>np.array</code> or the <code>pd.Series</code> the CPU needs to
follow all the string pointers, and jump to many random memory locations; which
is very cache inefficient. In <code>Polars</code> (<em>e.g.</em>, <code>Arrow</code> data
structure) strings are contiguous in memory and traversing is cache-optimal and
predictable for the CPU.</p>
<p>The string processing functions available in <code>Polars</code> are available in the
<a href="https://pola-rs.github.io/polars/py-polars/html/reference/series.html#strings"><code>str</code> namespace</a></p>
<p>A few examples below. To compute string lengths:</p>
<pre><code class="language-python">import polars as pl

df = pl.DataFrame({&quot;shakespeare&quot;: &quot;All that glitters is not gold&quot;.split(&quot; &quot;)})

df = df.with_column(pl.col(&quot;shakespeare&quot;).str.lengths().alias(&quot;letter_count&quot;))
</code></pre>
<p>returning:</p>
<pre><code class="language-text">shape: (6, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ shakespeare â”† letter_count â”‚
â”‚ ---         â”† ---          â”‚
â”‚ str         â”† u32          â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ All         â”† 3            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ that        â”† 4            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ glitters    â”† 8            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ is          â”† 2            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ not         â”† 3            â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ gold        â”† 4            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>And below a regex pattern to filter out articles (<code>the</code>, <code>a</code>, <code>and</code>, <em>etc.</em>) from a
sentence:</p>
<pre><code class="language-python">import polars as pl

df = pl.DataFrame({&quot;a&quot;: &quot;The man that ate a whole cake&quot;.split(&quot; &quot;)})

df = df.filter(pl.col(&quot;a&quot;).str.contains(r&quot;(?i)^the$|^a$&quot;).is_not())
</code></pre>
<p>yielding:</p>
<pre><code class="language-text">shape: (5, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚ a     â”‚
â”‚ ---   â”‚
â”‚ str   â”‚
â•â•â•â•â•â•â•â•â•¡
â”‚ man   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ that  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ ate   â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ whole â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ cake  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h1 id="timestamp-parsing"><a class="header" href="#timestamp-parsing">Timestamp parsing</a></h1>
<p><code>Polars</code> offers 3 time datatypes:</p>
<ul>
<li><code>pl.Date</code>, to be used for <strong>date</strong> objects: the number of days since the UNIX epoch as
a 32 bit signed integer.</li>
<li><code>pl.Datetime</code>, to be used of <strong>datetime</strong> ojects: the number of nanoseconds since the
UNIX epoch as a 64 bit signed integer.</li>
<li><code>pl.Time</code>, encoded as the number of nanoseconds since midnight.</li>
</ul>
<p><code>Polars</code> string (<code>pl.Utf8</code>) datatypes can be parsed as either of them. One can let
<code>Polars</code> try to guess the format of the date[time], or explicitly provide a <code>fmt</code>
rule.</p>
<p>For instance (check <a href="https://strftime.org/">this link</a> for an comprehensive list):</p>
<ul>
<li><code>&quot;%Y-%m-%d&quot;</code> for <code>&quot;2020-12-31&quot;</code></li>
<li><code>&quot;%Y/%B/%d&quot;</code> for <code>&quot;2020/December/31&quot;</code></li>
<li><code>&quot;%B %y&quot;</code> for <code>&quot;December 20&quot;</code></li>
</ul>
<p>Below a quick example:</p>
<pre><code class="language-python">import polars as pl

dataset = pl.DataFrame({&quot;date&quot;: [&quot;2020-01-02&quot;, &quot;2020-01-03&quot;, &quot;2020-01-04&quot;], &quot;index&quot;: [1, 2, 3]})

q = dataset.lazy().with_column(pl.col(&quot;date&quot;).str.strptime(pl.Date, &quot;%Y-%m-%d&quot;))

df = q.collect()
</code></pre>
<p>returning:</p>
<pre><code class="language-text">shape: (3, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ date       â”† index â”‚
â”‚ ---        â”† ---   â”‚
â”‚ date       â”† i64   â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ 2020-01-02 â”† 1     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2020-01-03 â”† 2     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2020-01-04 â”† 3     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>All datetime functionality is shown in the <a href="https://pola-rs.github.io/polars/py-polars/html/reference/series.html#timeseries"><code>dt</code> namespace</a>.</p>
<h1 id="performance"><a class="header" href="#performance">Performance</a></h1>
<p>This chapter handles some gotcha's needed to get maximum performance out of Polars.
When used properly, Polars can run at blazing speeds. Take a look at the results in
<a href="https://h2oai.github.io/db-benchmark/">H2O AI database benchmark</a>.</p>
<h1 id="strings"><a class="header" href="#strings">Strings</a></h1>
<p>Understanding the memory format used by <code>Arrow</code>/<code>Polars</code> can really increase performance
of your queries. This is especially true for large string data. The figure below shows
how an <code>Arrow</code> <code>UTF8</code> array is laid out in memory.</p>
<p>The array <code>[&quot;foo&quot;, &quot;bar&quot;, &quot;ham&quot;]</code> is encoded by :</p>
<ul>
<li>a concatenated string <code>&quot;foobarham&quot;</code>,</li>
<li>an offset array indicating the start (and end) of each string <code>[0, 2, 5, 8]</code>,</li>
<li>a null bitmap, indicating null values.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/arrow-string.svg" alt="" /></p>
<p>This memory structure is very cache-efficient if we are to read the string values.
Especially if we compare it to a <code>Vec&lt;String&gt;</code> (an array of heap allocated string data
in <code>Rust</code>).</p>
<p><img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/docs/pandas-string.svg" alt="" /></p>
<p>However, if we need to reorder the <code>Arrow</code> <code>UTF8</code> array, we need to swap around all the
bytes of the string values, which can become very expensive when dealing with large
strings. On the other hand, for the <code>Vec&lt;String&gt;</code>, we only need to swap pointers around
which is only 8 bytes data that have to be moved with little cost.</p>
<p>Reordering a <code>DataFrame</code> embedding a large number of <code>Utf8</code> <code>Series</code> due to an operation
(filtering, joining, grouping, <em>etc.</em>) can quickly become quite expensive.</p>
<h2 id="categorical-type"><a class="header" href="#categorical-type">Categorical type</a></h2>
<p>For this reason <code>Polars</code> has a <code>CategoricalType</code>. A <code>Categorical</code> <code>Series</code> is an array
filled with <code>u32</code> values that each represent a unique string value. Thereby maintaining
cache efficiency, whilst keeping cheap to move values around.</p>
<p>In the example below we show how you can cast an <code>Utf8</code> <code>Series</code> column to a
<code>Categorical</code> <code>Series</code>.</p>
<pre><code class="language-python">import polars as pl

df[&quot;utf8-column&quot;].cast(pl.Categorical)
</code></pre>
<h3 id="eager-join-multiple-dataframes-on-categorical-data"><a class="header" href="#eager-join-multiple-dataframes-on-categorical-data">Eager join multiple DataFrames on Categorical data</a></h3>
<p>When two DataFrames need to be joined based on string data the <code>Categorical</code> data needs
to be synchronized (data in column <code>A</code> of <code>df1</code> needs to point to the same underlying
string data as column <code>B</code> in <code>df2</code>). One can do so by casting data in the <code>StringCache</code>
context manager. This will synchronize all seen string values for the duration of that
context manager. If you want the global string cache to be existent during the whole
run, you can set <code>toggle_string_cache</code> to <code>True</code>.</p>
<pre><code class="language-python">import polars as pl

df1 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, &quot;ham&quot;], &quot;b&quot;: [1, 2, 3]})
df2 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;spam&quot;, &quot;eggs&quot;], &quot;c&quot;: [3, 2, 2]})

with pl.StringCache():
    df1.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))
    df2.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))
</code></pre>
<h3 id="lazy-join-multiple-dataframes-on-categorical-data"><a class="header" href="#lazy-join-multiple-dataframes-on-categorical-data">Lazy join multiple DataFrames on Categorical data</a></h3>
<p>A lazy query always has a global string cache (unless you opt-out) for the duration of
that query (until <code>.collect()</code> is called). The example below shows how you could join
two DataFrames with <code>Categorical</code> types.</p>
<pre><code class="language-python">import polars as pl

df1 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;bar&quot;, &quot;ham&quot;], &quot;b&quot;: [1, 2, 3]}).lazy()
df2 = pl.DataFrame({&quot;a&quot;: [&quot;foo&quot;, &quot;spam&quot;, &quot;eggs&quot;], &quot;c&quot;: [3, 2, 2]}).lazy()

df1 = df1.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))
df2 = df2.with_column(pl.col(&quot;a&quot;).cast(pl.Categorical))

df1.join(df2, on=&quot;a&quot;, how=&quot;inner&quot;)
</code></pre>
<h1 id="optimizations"><a class="header" href="#optimizations">Optimizations</a></h1>
<p>This chapter will investigate some of the optimizations that are applied by the Polars
query optimizer by going through some examples and see how Polars modifies the original query plan.</p>
<h1 id="lazy-api-1"><a class="header" href="#lazy-api-1">Lazy API</a></h1>
<blockquote>
<p>In redaction</p>
</blockquote>
<p>To demonstrate the lazy <code>Polars</code> capabilities we suggest to explore two medium-large
datasets of usernames:</p>
<p><a href="https://www.reddit.com/r/datasets/comments/9i8s5j/dataset_metadata_for_69_million_reddit_users_in/">Reddit usernames dataset</a>
containing 69+ million rows,</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

dataset = pl.read_csv(f&quot;{DATA_DIR}/reddit.csv&quot;, stop_after_n_rows=10)
</code></pre>
<pre><code class="language-text">shape: (5, 6)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id  â”† name                     â”† created_utc â”† updated_on â”† comment_karma â”† link_karma â”‚
â”‚ --- â”† ---                      â”† ---         â”† ---        â”† ---           â”† ---        â”‚
â”‚ i64 â”† str                      â”† i64         â”† i64        â”† i64           â”† i64        â”‚
â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1   â”† truman48lamb_jasonbroken â”† 1397113470  â”† 1536527864 â”† 0             â”† 0          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2   â”† johnethen06_jasonbroken  â”† 1397113483  â”† 1536527864 â”† 0             â”† 0          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3   â”† yaseinrez_jasonbroken    â”† 1397113483  â”† 1536527864 â”† 0             â”† 1          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 4   â”† Valve92_jasonbroken      â”† 1397113503  â”† 1536527864 â”† 0             â”† 0          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 5   â”† srbhuyan_jasonbroken     â”† 1397113506  â”† 1536527864 â”† 0             â”† 0          â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>and the <a href="https://github.com/RuneStar/name-cleanup-2014">Runescape username dataset</a>
containing about 55+ million records.</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

dataset = pl.read_csv(f&quot;{DATA_DIR}/runescape.csv&quot;, has_headers=False, stop_after_n_rows=10)
</code></pre>
<pre><code class="language-text">shape: (5, 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ column_1    â”‚
â”‚ ---         â”‚
â”‚ str         â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ a000        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ a0000       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ a000000     â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ a0000000    â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ a0000000000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h1 id="predicate-pushdown"><a class="header" href="#predicate-pushdown">Predicate pushdown</a></h1>
<blockquote>
<p>In redaction</p>
</blockquote>
<p>Predicate pushdown is an optimization Polars does that reduces query times and memory
usage. A predicate is database jargon for applying a filter on some table and thereby
reducing the number of rows on that table.</p>
<p>So let's see if we can load some Reddit data and filter on a few predicates.</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

q1 = (
    pl.scan_csv(f&quot;{DATA_DIR}/reddit.csv&quot;)
    .filter(pl.col(&quot;comment_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;link_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;name&quot;).str.contains(r&quot;^a&quot;))  # filter name that start with an &quot;a&quot;
)
</code></pre>
<p>If we were to run this query above, nothing would happen! This due to the lazy evaluation,
nothing will happen until specifically requested. This allows Polars to see the whole
context of a query and optimize just in time for execution.</p>
<p>Execution is requested by the <code>.collect</code> method. This would query all available data.
During writing/ optimizing/ checking your query this is often not what you want. Another
method that calls for execution is the <code>.fetch</code> method. <code>.fetch</code> takes a parameter
<code>n_rows</code> and tries to 'fetch' that number of rows at the data source (no guarantees are
given though).</p>
<p>So let's &quot;fetch&quot; ~10 Million rows from the source file and apply the predicates.</p>
<pre><code class="language-python">q1.fetch(n_rows=int(1e7))
</code></pre>
<pre><code class="language-text">shape: (656, 6)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id      â”† name        â”† created_utc â”† updated_on â”† comment_karma â”† link_karma â”‚
â”‚ ---     â”† ---         â”† ---         â”† ---        â”† ---           â”† ---        â”‚
â”‚ i64     â”† str         â”† i64         â”† i64        â”† i64           â”† i64        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 77860   â”† aquarin     â”† 1137474000  â”† 1536528294 â”† 150           â”† 11         â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 77974   â”† aadvaark    â”† 1137301200  â”† 1536528294 â”† 26            â”† 47         â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 78004   â”† apoisel     â”† 1137301200  â”† 1536497404 â”† 42            â”† 2549       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 78041   â”† aonic       â”† 1137301200  â”† 1536497404 â”† 2931          â”† 2095       â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ ...     â”† ...         â”† ...         â”† ...        â”† ...           â”† ...        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 1192656 â”† atothedrian â”† 1162785880  â”† 1536497412 â”† 748           â”† 585        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 1204607 â”† akbusiness  â”† 1162899425  â”† 1536532995 â”† 73            â”† 512        â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 1214809 â”† aaminics    â”† 1162969322  â”† 1536533034 â”† 22            â”† 6          â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 1225341 â”† antonulrich â”† 1163110623  â”† 1536497412 â”† 9304          â”† 1782       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Above we see that from the 10 Million rows, 61503 rows match our predicate.</p>
<h2 id="break-it-down"><a class="header" href="#break-it-down">Break it down</a></h2>
<p>In Polars we can visualize the query plan. Let's take a look.</p>
<pre><code class="language-python">q1.show_graph(optimized=False)
</code></pre>
<p><img src="optimizations/lazy/../../outputs/predicate_pushdown/graph1.png" alt="" /></p>
<p>The astute reader maybe would notice that our query is not very optimal because we have
3 separate <em>FILTER</em> nodes. That means that after every <em>FILTER</em> a new DataFrame is
allocated, which will be input to the next <em>FILTER</em> and then deleted from memory, that
must be redundant. And you know what.. He/she is right, the predicates should be
combined, we should have written this query:</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

q2 = pl.scan_csv(f&quot;{DATA_DIR}/reddit.csv&quot;).filter(
    (pl.col(&quot;comment_karma&quot;) &gt; 0) &amp; (pl.col(&quot;link_karma&quot;) &gt; 0) &amp; (pl.col(&quot;name&quot;).str.contains(r&quot;^a&quot;))
)
</code></pre>
<p>That would translate to:</p>
<pre><code class="language-python">q2.show_graph(optimized=False)
</code></pre>
<p><img src="optimizations/lazy/../../outputs/predicate_pushdown/graph2.png" alt="" /></p>
<p>As we can see the predicates are combined. This would lead to less copying of data</p>
<h2 id="in-comes-optimization"><a class="header" href="#in-comes-optimization">In comes optimization</a></h2>
<p>Polars tries to save that mental overhead from the query writer and combines predicates
for you. Besides that, it pushes predicates down to the scan level! Let's see how our
optimized query looks.</p>
<pre><code class="language-python">q1.show_graph(optimized=True)
</code></pre>
<p><img src="optimizations/lazy/../../outputs/predicate_pushdown/graph1-optimized.png" alt="" /></p>
<p>It may be hard to see, but what is clear is that there is only a single node; the <em>CSV
SCAN</em>. The predicate filtering is done during the reading of the csv. This means that
this query's memory overhead is reduced by filtering factor! This makes a huge impact.</p>
<h3 id="memory"><a class="header" href="#memory">Memory</a></h3>
<p>As we have seen there were ~ 62,000 rows left after the <em>FILTER</em>. That means that (aside
for some memory overhead of the batch size and filter operations) we use \(
\frac{6.2\text{e-}4}{1\text{e-}7} \sim 0.6 \text{%} \) of the memory we would
during an eager evaluation where we first would read the whole table in memory before
applying a filter.</p>
<h3 id="performance-1"><a class="header" href="#performance-1">Performance</a></h3>
<p>At the time of writing this, the predicate pushdown also increased the query time
performance.</p>
<p><strong>Without optimization</strong>, <code>predicate_pushdown=False</code> flag:</p>
<pre><code class="language-text">real	0m2,401s
user	0m5,457s
sys	0m0,894s
</code></pre>
<p><strong>with optimization</strong>, <code>predicate_pushdown=True</code> flag:</p>
<pre><code class="language-text">real	0m1,597s
user	0m6,143s
sys	0m0,647s
</code></pre>
<h2 id="relational-algebra"><a class="header" href="#relational-algebra">Relational algebra</a></h2>
<p>In the visualization of the query plan, you see a \( \sigma \) symbol. This indicates
a Predicate done at the <em>SCAN</em> level. There is also a \( \pi \) symbol indicating
projection (database jargon for column selection), but we'll get to that later.</p>
<h2 id="cheaper-joins"><a class="header" href="#cheaper-joins">Cheaper joins</a></h2>
<p>Predicate pushdown optimization will generally also lead to cheaper join's. A join is
an expensive operation, the fewer rows we have in a join operation the cheaper
it will become.</p>
<h1 id="projection-pushdown"><a class="header" href="#projection-pushdown">Projection pushdown</a></h1>
<blockquote>
<p>In redaction</p>
</blockquote>
<p>Let's expand our query from the previous section by joining the result of the <em>FILTER</em>
operation with the runescape data to see which popular Reddit username that have a
username starting with an a also played Runescape. That must be something we are all
interested in!</p>
<p>The query that does so may look like this.</p>
<pre><code class="language-python">import polars as pl

from ..paths import DATA_DIR

reddit = (
    pl.scan_csv(f&quot;{DATA_DIR}/reddit.csv&quot;)
    .filter(pl.col(&quot;comment_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;link_karma&quot;) &gt; 0)
    .filter(pl.col(&quot;name&quot;).str.contains(r&quot;^a&quot;))
)

runescape = pl.scan_csv(&quot;data/runescape.csv&quot;, has_headers=False).select(pl.col(&quot;column_1&quot;).alias(&quot;name&quot;))

dataset = reddit.join(runescape, on=&quot;name&quot;, how=&quot;inner&quot;).select([&quot;name&quot;, &quot;comment_karma&quot;, &quot;link_karma&quot;])

df1 = dataset.fetch(int(1e7))
df2 = dataset.fetch(int(1e7), predicate_pushdown=True, projection_pushdown=True)
</code></pre>
<p>And yields the following DataFrame.</p>
<pre><code class="language-text">shape: (0, 3)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ name â”† comment_karma â”† link_karma â”‚
â”‚ ---  â”† ---           â”† ---        â”‚
â”‚ str  â”† i64           â”† i64        â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2 id="break-it-down-1"><a class="header" href="#break-it-down-1">Break it down</a></h2>
<p>Again, let's take a look the query plan.</p>
<pre><code class="language-python">dataset.show_graph(optimized=False)
</code></pre>
<p><img src="optimizations/lazy/./../outputs/projection_pushdown/graph.png" alt="" /></p>
<p>Now were focussed on the projection's indicated with Ï€. The first node shows Ï€ 3/6,
indicating that we select 3 out of 6 columns in the DataFrame. If we look the csv scans
we see a wildcard Ï€ */6 and Ï€ */1 meaning that we select all of 6 columns of the
reddit dataset and the one and only column from the runescape dataset respectively.</p>
<p>This query is not very optimal. We select all columns from both datasets and only show
3/6 after join. That means that there were some columns computed during the join
operation that could have been ignored. There were also columns parsed during csv
scanning only to be dropped at the end. When we are dealing with DataFrame's with a
large number of columns the redundant work that is done can be huge.</p>
<h3 id="optimized-query"><a class="header" href="#optimized-query">Optimized query</a></h3>
<p>Let's see how Polars optimizes this query.</p>
<pre><code class="language-python">dataset.show_graph(optimized=True)
</code></pre>
<p><img src="optimizations/lazy/./../outputs/projection_pushdown/graph-optimized.png" alt="" /></p>
<p>The projections are pushed down the join operation all the way to the csv scans. This
means that both the scanning and join operation have become cheaper due to the query
optimization.</p>
<h2 id="performance-2"><a class="header" href="#performance-2">Performance</a></h2>
<p>Let's time the result before and after optimization.</p>
<p><strong>without optimization</strong>, <code>predicate_pushdown=False</code> and <code>projection_pushdown=False</code>.</p>
<pre><code class="language-text">real	0m3,273s
user	0m9,284s
sys	0m1,081s
</code></pre>
<p><strong>with optimization</strong>, <code>predicate_pushdown</code> and <code>projection_pushdown</code> flags both to
<code>True</code>.</p>
<pre><code class="language-text">real	0m1,732s
user	0m7,581s
sys	0m0,783s
</code></pre>
<p>We can see that we almost reduced query time by half on this simple query. With real
business data often comprising of many column, filtering missing data, doing complex
groupby and joins we expect this difference between unoptimized queries and optimized
queries to only grow.</p>
<h1 id="other-optimizations"><a class="header" href="#other-optimizations">Other optimizations</a></h1>
<blockquote>
<p>In redaction</p>
</blockquote>
<p>Besides predicate and projection pushdown, Polars does other optimizations.</p>
<p>One important one is optional caching and parallelization. One can imagine having two
different DataFrame computations that lead to a scan of the same file. Polars may cache
the scanned file to prevent scanning the same file twice. However, if you want to, you
may override this behavior and force polars to read the same file. This could be faster
because the scan could be done in parallel.</p>
<h2 id="join-parallelization"><a class="header" href="#join-parallelization">Join parallelization</a></h2>
<p>If we look at the previous query, we see that the join operation has as input a
computation path with <code>data/reddit.csv</code> as root and one path with <code>data/runescape.csv</code>
as root. Polars can observe that there are no dependencies between the two DataFrame and
will read both files in parallel. If other operations are done before the join (e.g.
groupby, filters, etc.) they are also executed in parallel.</p>
<p><img src="optimizations/lazy/../../outputs/projection_pushdown/graph-optimized.png" alt="" /></p>
<h2 id="simplify-expressions"><a class="header" href="#simplify-expressions">Simplify expressions</a></h2>
<p>Some other optimizations that are done are expression simplifications. The impact of
these optimizations is less than that of predicate and projection pushdown, but they
likely add up. You can
<a href="https://github.com/pola-rs/polars/issues/139">track this issue</a> to see the latest
status of those.</p>
<h1 id="reference-guide"><a class="header" href="#reference-guide">Reference guide</a></h1>
<p>Need to see all available methods/functions of <code>Polars</code>? Choose the right documentation
entrypoint below:</p>
<ul>
<li><a href="https://docs.rs/polars"><code>Rust</code> release</a></li>
<li><a href="https://pola-rs.github.io/polars/py-polars/html/reference"><code>Python</code> API</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
